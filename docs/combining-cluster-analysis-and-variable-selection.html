<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>2.5 Combining cluster analysis and variable selection | book.utf8.md</title>
  <meta name="description" content="PdD thesis">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="2.5 Combining cluster analysis and variable selection | book.utf8.md />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="PdD thesis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.5 Combining cluster analysis and variable selection | book.utf8.md />
  
  <meta name="twitter:description" content="PdD thesis" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="non-parametric.html">
<link rel="next" href="hypothesis.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical learning for omics association and interactions studies based on blockwise feature compression</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i>General introduction</a></li>
<li class="chapter" data-level="" data-path="notations.html"><a href="notations.html"><i class="fa fa-check"></i>Notations</a></li>
<li class="chapter" data-level="" data-path="abbreviations.html"><a href="abbreviations.html"><i class="fa fa-check"></i>Abbreviations</a></li>
<li class="chapter" data-level="1" data-path="genet.html"><a href="genet.html"><i class="fa fa-check"></i><b>1</b> Basic concepts of molecular genetics</a><ul>
<li class="chapter" data-level="1.1" data-path="genome.html"><a href="genome.html"><i class="fa fa-check"></i><b>1.1</b> Genome description</a></li>
<li class="chapter" data-level="1.2" data-path="genome-sequencing.html"><a href="genome-sequencing.html"><i class="fa fa-check"></i><b>1.2</b> Genome sequencing</a><ul>
<li class="chapter" data-level="1.2.1" data-path="genome-sequencing.html"><a href="genome-sequencing.html#DNAseq"><i class="fa fa-check"></i><b>1.2.1</b> DNA sequencing</a></li>
<li class="chapter" data-level="1.2.2" data-path="genome-sequencing.html"><a href="genome-sequencing.html#sequence-assembly"><i class="fa fa-check"></i><b>1.2.2</b> Sequence assembly</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html"><i class="fa fa-check"></i><b>1.3</b> DNA polymorphism</a><ul>
<li class="chapter" data-level="1.3.1" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html#restriction-fragment-length-polymorphisms-rflp"><i class="fa fa-check"></i><b>1.3.1</b> Restriction Fragment Length Polymorphisms (RFLP)</a></li>
<li class="chapter" data-level="1.3.2" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html#simple-sequence-length-polymorphisms-sslp"><i class="fa fa-check"></i><b>1.3.2</b> Simple Sequence Length Polymorphisms (SSLP)</a></li>
<li class="chapter" data-level="1.3.3" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html#single-nucleotide-polymorphisms-snp"><i class="fa fa-check"></i><b>1.3.3</b> Single Nucleotide Polymorphisms (SNP)</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="linkage.html"><a href="linkage.html"><i class="fa fa-check"></i><b>1.4</b> Linkage and partial linkage for genetic mapping</a></li>
<li class="chapter" data-level="1.5" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html"><i class="fa fa-check"></i><b>1.5</b> Basic concepts in population genetics</a><ul>
<li class="chapter" data-level="1.5.1" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html#HWE"><i class="fa fa-check"></i><b>1.5.1</b> Hardy-Weinberg equilibrium in large population</a></li>
<li class="chapter" data-level="1.5.2" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html#genetic-drift-in-small-population"><i class="fa fa-check"></i><b>1.5.2</b> Genetic drift in small population</a></li>
<li class="chapter" data-level="1.5.3" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html#concept-of-heritability"><i class="fa fa-check"></i><b>1.5.3</b> Concept of heritability</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="LD.html"><a href="LD.html"><i class="fa fa-check"></i><b>1.6</b> Linkage disequilibrium</a><ul>
<li class="chapter" data-level="1.6.1" data-path="LD.html"><a href="LD.html#definition"><i class="fa fa-check"></i><b>1.6.1</b> Definition</a></li>
<li class="chapter" data-level="1.6.2" data-path="LD.html"><a href="LD.html#measure-of-ld"><i class="fa fa-check"></i><b>1.6.2</b> Measure of LD</a></li>
<li class="chapter" data-level="1.6.3" data-path="LD.html"><a href="LD.html#estimation-of-linkage-disequilibrium"><i class="fa fa-check"></i><b>1.6.3</b> Estimation of linkage disequilibrium</a></li>
<li class="chapter" data-level="1.6.4" data-path="LD.html"><a href="LD.html#origins-of-linkage-disequilibrium"><i class="fa fa-check"></i><b>1.6.4</b> Origins of linkage disequilibrium</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="haplo.html"><a href="haplo.html"><i class="fa fa-check"></i><b>1.7</b> Structure of haplotype blocks in the human genome</a><ul>
<li class="chapter" data-level="" data-path="haplo.html"><a href="haplo.html#definition-of-haplotype-blocks"><i class="fa fa-check"></i>Definition of haplotype blocks</a></li>
<li class="chapter" data-level="" data-path="haplo.html"><a href="haplo.html#patterns-in-human-genome"><i class="fa fa-check"></i>Patterns in human genome</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="stat.html"><a href="stat.html"><i class="fa fa-check"></i><b>2</b> Statistical context</a><ul>
<li class="chapter" data-level="2.1" data-path="notations-1.html"><a href="notations-1.html"><i class="fa fa-check"></i><b>2.1</b> Notations</a></li>
<li class="chapter" data-level="2.2" data-path="concepts-of-statistical-learning.html"><a href="concepts-of-statistical-learning.html"><i class="fa fa-check"></i><b>2.2</b> Concepts of statistical learning</a><ul>
<li class="chapter" data-level="2.2.1" data-path="concepts-of-statistical-learning.html"><a href="concepts-of-statistical-learning.html#prediction"><i class="fa fa-check"></i><b>2.2.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="parametric.html"><a href="parametric.html"><i class="fa fa-check"></i><b>2.3</b> Parametric methods</a><ul>
<li class="chapter" data-level="2.3.1" data-path="parametric.html"><a href="parametric.html#linmod"><i class="fa fa-check"></i><b>2.3.1</b> Linear models</a></li>
<li class="chapter" data-level="2.3.2" data-path="parametric.html"><a href="parametric.html#penalized"><i class="fa fa-check"></i><b>2.3.2</b> Penalized linear regression</a></li>
<li class="chapter" data-level="2.3.3" data-path="parametric.html"><a href="parametric.html#glm"><i class="fa fa-check"></i><b>2.3.3</b> Generalized linear models</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="non-parametric.html"><a href="non-parametric.html"><i class="fa fa-check"></i><b>2.4</b> Splines and generalized additive models: Moving beyond linearit</a><ul>
<li class="chapter" data-level="2.4.1" data-path="non-parametric.html"><a href="non-parametric.html#introduction"><i class="fa fa-check"></i><b>2.4.1</b> Introduction</a></li>
<li class="chapter" data-level="2.4.2" data-path="non-parametric.html"><a href="non-parametric.html#splines"><i class="fa fa-check"></i><b>2.4.2</b> Regression splines</a></li>
<li class="chapter" data-level="2.4.3" data-path="non-parametric.html"><a href="non-parametric.html#mathrmb-splines"><i class="fa fa-check"></i><b>2.4.3</b> <span class="math inline">\(\mathrm{B}\)</span>-splines</a></li>
<li class="chapter" data-level="2.4.4" data-path="non-parametric.html"><a href="non-parametric.html#smoothing"><i class="fa fa-check"></i><b>2.4.4</b> Cubic smoothing splines</a></li>
<li class="chapter" data-level="2.4.5" data-path="non-parametric.html"><a href="non-parametric.html#gam"><i class="fa fa-check"></i><b>2.4.5</b> Generalized additive models (GAM)</a></li>
<li class="chapter" data-level="2.4.6" data-path="non-parametric.html"><a href="non-parametric.html#hgam"><i class="fa fa-check"></i><b>2.4.6</b> High-dimensional generalized additive models (HGAM)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html"><i class="fa fa-check"></i><b>2.5</b> Combining cluster analysis and variable selection</a><ul>
<li class="chapter" data-level="2.5.1" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html#CAH"><i class="fa fa-check"></i><b>2.5.1</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="2.5.2" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html#HCAR"><i class="fa fa-check"></i><b>2.5.2</b> Hierarchical Clustering and Averaging Regression</a></li>
<li class="chapter" data-level="2.5.3" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html#MLGL"><i class="fa fa-check"></i><b>2.5.3</b> Multi-Layer Group-Lasso (MLGL)</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="hypothesis.html"><a href="hypothesis.html"><i class="fa fa-check"></i><b>2.6</b> Statistical testing of significance</a><ul>
<li class="chapter" data-level="2.6.1" data-path="hypothesis.html"><a href="hypothesis.html#introduction-1"><i class="fa fa-check"></i><b>2.6.1</b> Introduction</a></li>
<li class="chapter" data-level="2.6.2" data-path="hypothesis.html"><a href="hypothesis.html#chi2"><i class="fa fa-check"></i><b>2.6.2</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="2.6.3" data-path="hypothesis.html"><a href="hypothesis.html#LRT"><i class="fa fa-check"></i><b>2.6.3</b> Likelihood ratio test</a></li>
<li class="chapter" data-level="2.6.4" data-path="hypothesis.html"><a href="hypothesis.html#pvalGAM"><i class="fa fa-check"></i><b>2.6.4</b> Calculation of <em>p</em>-values in GAM</a></li>
<li class="chapter" data-level="2.6.5" data-path="hypothesis.html"><a href="hypothesis.html#multiple"><i class="fa fa-check"></i><b>2.6.5</b> Multiple testing comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="asso.html"><a href="asso.html"><i class="fa fa-check"></i><b>3</b> Genome-Wide Association Studies</a><ul>
<li class="chapter" data-level="3.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="genoquality.html"><a href="genoquality.html"><i class="fa fa-check"></i><b>3.2</b> Genotype quality control</a><ul>
<li class="chapter" data-level="3.2.1" data-path="genoquality.html"><a href="genoquality.html#deviation-from-hwe."><i class="fa fa-check"></i><b>3.2.1</b> Deviation from HWE.</a></li>
<li class="chapter" data-level="3.2.2" data-path="genoquality.html"><a href="genoquality.html#missing-data."><i class="fa fa-check"></i><b>3.2.2</b> Missing data.</a></li>
<li class="chapter" data-level="3.2.3" data-path="genoquality.html"><a href="genoquality.html#distribution-of-test-statistics."><i class="fa fa-check"></i><b>3.2.3</b> Distribution of test statistics.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="OR.html"><a href="OR.html"><i class="fa fa-check"></i><b>3.3</b> Disease penetrance and odds ratio</a></li>
<li class="chapter" data-level="3.4" data-path="SMA.html"><a href="SMA.html"><i class="fa fa-check"></i><b>3.4</b> Single Marker Analysis</a><ul>
<li class="chapter" data-level="3.4.1" data-path="SMA.html"><a href="SMA.html#pearsons-chi2-statistic"><i class="fa fa-check"></i><b>3.4.1</b> Pearson’s <span class="math inline">\(\chi^2\)</span> statistic</a></li>
<li class="chapter" data-level="3.4.2" data-path="SMA.html"><a href="SMA.html#cochran-armitage-trend-test"><i class="fa fa-check"></i><b>3.4.2</b> Cochran-Armitage trend test</a></li>
<li class="chapter" data-level="3.4.3" data-path="SMA.html"><a href="SMA.html#logitGWAS"><i class="fa fa-check"></i><b>3.4.3</b> Logistic regression and likelihood ratio test</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="GWASlimits.html"><a href="GWASlimits.html"><i class="fa fa-check"></i><b>3.5</b> Limitations</a></li>
<li class="chapter" data-level="3.6" data-path="popstructure.html"><a href="popstructure.html"><i class="fa fa-check"></i><b>3.6</b> Population structure</a><ul>
<li class="chapter" data-level="3.6.1" data-path="popstructure.html"><a href="popstructure.html#genomic-control"><i class="fa fa-check"></i><b>3.6.1</b> Genomic control</a></li>
<li class="chapter" data-level="3.6.2" data-path="popstructure.html"><a href="popstructure.html#structured-association"><i class="fa fa-check"></i><b>3.6.2</b> Structured association</a></li>
<li class="chapter" data-level="3.6.3" data-path="popstructure.html"><a href="popstructure.html#PCC"><i class="fa fa-check"></i><b>3.6.3</b> Principle components correction</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="multiloc.html"><a href="multiloc.html"><i class="fa fa-check"></i><b>3.7</b> Multi-locus analysis</a><ul>
<li class="chapter" data-level="3.7.1" data-path="multiloc.html"><a href="multiloc.html#haplotype-based-approaches"><i class="fa fa-check"></i><b>3.7.1</b> Haplotype-based approaches</a></li>
<li class="chapter" data-level="3.7.2" data-path="multiloc.html"><a href="multiloc.html#rare-variant"><i class="fa fa-check"></i><b>3.7.2</b> Rare-variant association analysis</a></li>
<li class="chapter" data-level="3.7.3" data-path="multiloc.html"><a href="multiloc.html#adjclust"><i class="fa fa-check"></i><b>3.7.3</b> LD based approach to variable selection in GWAS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="LEOS.html"><a href="LEOS.html"><i class="fa fa-check"></i><b>4</b> Learning the Optimal in GWAS through hierarchical SNP aggregation</a><ul>
<li class="chapter" data-level="4.1" data-path="introleos.html"><a href="introleos.html"><i class="fa fa-check"></i><b>4.1</b> Related work</a></li>
<li class="chapter" data-level="4.2" data-path="leosmethod.html"><a href="leosmethod.html"><i class="fa fa-check"></i><b>4.2</b> Method</a><ul>
<li class="chapter" data-level="4.2.1" data-path="leosmethod.html"><a href="leosmethod.html#CHAC"><i class="fa fa-check"></i><b>4.2.1</b> Step 1. Constrained-HAC</a></li>
<li class="chapter" data-level="4.2.2" data-path="leosmethod.html"><a href="leosmethod.html#Dstar"><i class="fa fa-check"></i><b>4.2.2</b> Step 2. Dimension reduction function</a></li>
<li class="chapter" data-level="4.2.3" data-path="leosmethod.html"><a href="leosmethod.html#cutree"><i class="fa fa-check"></i><b>4.2.3</b> Step 3. Optimal number of groups estimation</a></li>
<li class="chapter" data-level="4.2.4" data-path="leosmethod.html"><a href="leosmethod.html#step4"><i class="fa fa-check"></i><b>4.2.4</b> Step 4. Multiple testing on aggregated-SNP variables</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="numsim.html"><a href="numsim.html"><i class="fa fa-check"></i><b>4.3</b> Numerical simulations</a><ul>
<li class="chapter" data-level="4.3.1" data-path="numsim.html"><a href="numsim.html#simupheno"><i class="fa fa-check"></i><b>4.3.1</b> Simulation of the case-control phenotype</a></li>
<li class="chapter" data-level="4.3.2" data-path="numsim.html"><a href="numsim.html#perfeval"><i class="fa fa-check"></i><b>4.3.2</b> Performance evaluation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>4.4</b> Results</a><ul>
<li class="chapter" data-level="4.4.1" data-path="results.html"><a href="results.html#results-and-discussions-of-the-numerical-simulations"><i class="fa fa-check"></i><b>4.4.1</b> Results and discussions of the numerical simulations</a></li>
<li class="chapter" data-level="4.4.2" data-path="results.html"><a href="results.html#performance-results-for-simulated-data."><i class="fa fa-check"></i><b>4.4.2</b> Performance results for simulated data.</a></li>
<li class="chapter" data-level="4.4.3" data-path="results.html"><a href="results.html#leosappli"><i class="fa fa-check"></i><b>4.4.3</b> Application in Wellcome Trust Case Control Consortium(WTCCC) and Ankylosing Spondylitis (AS) studies</a></li>
<li class="chapter" data-level="4.4.4" data-path="results.html"><a href="results.html#realdata"><i class="fa fa-check"></i><b>4.4.4</b> Results in WTCCC and AS studies</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="leosgam.html"><a href="leosgam.html"><i class="fa fa-check"></i><b>4.5</b> Generalized additive models in GWAS</a><ul>
<li class="chapter" data-level="4.5.1" data-path="leosgam.html"><a href="leosgam.html#comparison-of-predictive-power"><i class="fa fa-check"></i><b>4.5.1</b> Comparison of predictive power</a></li>
<li class="chapter" data-level="4.5.2" data-path="leosgam.html"><a href="leosgam.html#results-of-univariate-smoothing-splines-on-aggregated-snp"><i class="fa fa-check"></i><b>4.5.2</b> Results of univariate smoothing splines on aggregated-SNP</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="discussions.html"><a href="discussions.html"><i class="fa fa-check"></i><b>4.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sicomore.html"><a href="sicomore.html"><i class="fa fa-check"></i><b>5</b> Selection of interaction effects in compressed multiple omics representation</a><ul>
<li class="chapter" data-level="5.1" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a><ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-3.html"><a href="introduction-3.html#background-1"><i class="fa fa-check"></i><b>5.1.1</b> Background</a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-3.html"><a href="introduction-3.html#combining-genome-and-metagenome-analyses."><i class="fa fa-check"></i><b>5.1.2</b> Combining genome and metagenome analyses.</a></li>
<li class="chapter" data-level="5.1.3" data-path="introduction-3.html"><a href="introduction-3.html#taking-structures-into-account-in-association-studies."><i class="fa fa-check"></i><b>5.1.3</b> Taking structures into account in association studies.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="modelsicomore.html"><a href="modelsicomore.html"><i class="fa fa-check"></i><b>5.2</b> Learning with complementary datasets</a><ul>
<li class="chapter" data-level="5.2.1" data-path="modelsicomore.html"><a href="modelsicomore.html#setting-and-notations"><i class="fa fa-check"></i><b>5.2.1</b> Setting and notations</a></li>
<li class="chapter" data-level="5.2.2" data-path="modelsicomore.html"><a href="modelsicomore.html#interactions-in-linear-models"><i class="fa fa-check"></i><b>5.2.2</b> Interactions in linear models</a></li>
<li class="chapter" data-level="5.2.3" data-path="modelsicomore.html"><a href="modelsicomore.html#compressdata"><i class="fa fa-check"></i><b>5.2.3</b> Compact model</a></li>
<li class="chapter" data-level="5.2.4" data-path="modelsicomore.html"><a href="modelsicomore.html#recoverinteractions"><i class="fa fa-check"></i><b>5.2.4</b> Recovering relevant interactions</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="implementation.html"><a href="implementation.html"><i class="fa fa-check"></i><b>5.3</b> Method</a><ul>
<li class="chapter" data-level="5.3.1" data-path="implementation.html"><a href="implementation.html#preprocess"><i class="fa fa-check"></i><b>5.3.1</b> Preprocessing of the data</a></li>
<li class="chapter" data-level="5.3.2" data-path="implementation.html"><a href="implementation.html#preprocessing-of-metagenomic-data"><i class="fa fa-check"></i><b>5.3.2</b> Preprocessing of metagenomic data</a></li>
<li class="chapter" data-level="5.3.3" data-path="implementation.html"><a href="implementation.html#structure"><i class="fa fa-check"></i><b>5.3.3</b> Structuring the data</a></li>
<li class="chapter" data-level="5.3.4" data-path="implementation.html"><a href="implementation.html#using-the-structure-efficiently"><i class="fa fa-check"></i><b>5.3.4</b> Using the structure efficiently</a></li>
<li class="chapter" data-level="5.3.5" data-path="implementation.html"><a href="implementation.html#identification-of-relevant-supervariables"><i class="fa fa-check"></i><b>5.3.5</b> Identification of relevant supervariables</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="XPsimu.html"><a href="XPsimu.html"><i class="fa fa-check"></i><b>5.4</b> Numerical simulations</a><ul>
<li class="chapter" data-level="5.4.1" data-path="XPsimu.html"><a href="XPsimu.html#data-generation"><i class="fa fa-check"></i><b>5.4.1</b> Data generation</a></li>
<li class="chapter" data-level="5.4.2" data-path="XPsimu.html"><a href="XPsimu.html#generation-of-the-phenotype"><i class="fa fa-check"></i><b>5.4.2</b> Generation of the phenotype</a></li>
<li class="chapter" data-level="5.4.3" data-path="XPsimu.html"><a href="XPsimu.html#comparison-of-methods"><i class="fa fa-check"></i><b>5.4.3</b> Comparison of methods</a></li>
<li class="chapter" data-level="5.4.4" data-path="XPsimu.html"><a href="XPsimu.html#evaluation-metrics"><i class="fa fa-check"></i><b>5.4.4</b> Evaluation metrics</a></li>
<li class="chapter" data-level="5.4.5" data-path="XPsimu.html"><a href="XPsimu.html#performance-results"><i class="fa fa-check"></i><b>5.4.5</b> Performance results</a></li>
<li class="chapter" data-level="5.4.6" data-path="XPsimu.html"><a href="XPsimu.html#computational-time"><i class="fa fa-check"></i><b>5.4.6</b> Computational time</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="XPINRA.html"><a href="XPINRA.html"><i class="fa fa-check"></i><b>5.5</b> Application on real data: rhizosphere of <em>Medicago truncatula</em></a><ul>
<li class="chapter" data-level="5.5.1" data-path="XPINRA.html"><a href="XPINRA.html#material"><i class="fa fa-check"></i><b>5.5.1</b> Material</a></li>
<li class="chapter" data-level="5.5.2" data-path="XPINRA.html"><a href="XPINRA.html#analysis"><i class="fa fa-check"></i><b>5.5.2</b> Analysis</a></li>
<li class="chapter" data-level="5.5.3" data-path="XPINRA.html"><a href="XPINRA.html#results-1"><i class="fa fa-check"></i><b>5.5.3</b> Results</a></li>
<li class="chapter" data-level="5.5.4" data-path="XPINRA.html"><a href="XPINRA.html#results-on-root-shoot-ratio"><i class="fa fa-check"></i><b>5.5.4</b> Results on Root Shoot Ratio</a></li>
<li class="chapter" data-level="5.5.5" data-path="XPINRA.html"><a href="XPINRA.html#results-on-specific-nitrogen-uptake"><i class="fa fa-check"></i><b>5.5.5</b> Results on Specific Nitrogen Uptake</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="discussions-1.html"><a href="discussions-1.html"><i class="fa fa-check"></i><b>5.6</b> Discussions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i>Conclusions</a><ul>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html#discussions-on-leos-algorithm"><i class="fa fa-check"></i>Discussions on LEOS algorithm</a></li>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html#discussions-on-sicomore-algorithm"><i class="fa fa-check"></i>Discussions on SICOMORE algorithm</a></li>
<li class="chapter" data-level="" data-path="perspectives.html"><a href="perspectives.html"><i class="fa fa-check"></i>Perspectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="annexes.html"><a href="annexes.html"><i class="fa fa-check"></i>Annexes</a><ul>
<li class="chapter" data-level="" data-path="biasvar.html"><a href="biasvar.html"><i class="fa fa-check"></i>Derivation of the MSE bias-variance decomposition</a></li>
<li class="chapter" data-level="" data-path="computational-aspect-of-splines-calculation.html"><a href="computational-aspect-of-splines-calculation.html"><i class="fa fa-check"></i>Computational aspect of splines calculation</a><ul>
<li><a href="computational-aspect-of-splines-calculation.html#linsmooth">Linear smoother <span class="citation">(Buja, Hastie, and Tibshirani <span>1989</span>)</span></a></li>
<li><a href="computational-aspect-of-splines-calculation.html#lambdasmooth">Smoothing parameter <span class="math inline">\(\lambda\)</span> for smoothing splines</a></li>
<li><a href="computational-aspect-of-splines-calculation.html#Bspline"><span class="math inline">\(\mathit{B}\)</span>-spline basis</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="combining-cluster-analysis-and-variable-selection" class="section level2">
<h2><span class="header-section-number">2.5</span> Combining cluster analysis and variable selection</h2>
<div id="CAH" class="section level3">
<h3><span class="header-section-number">2.5.1</span> Hierarchical clustering</h3>
<p>Hierarchical clustering is a method of cluster analysis which aims at
building a hierarchy of clusters and result in a tree-based
representation of the observations called a <em>dendrogram</em>. The term
hierarchical refers to the fact that clusters obtained by cutting the
dendrogram at a given height are necessarily nested within the clusters
obtained by cutting the dendrogram at any greater height.</p>
<p>Strategies for hierarchical clustering generally fall into two types
<span class="citation">(Rokach and Maimon <a href="#ref-rokach2005clustering">2005</a>)</span>:</p>
<ul>
<li><p>Agglomerative: This is a “bottom up” approach where each observation
starts in its own cluster, and pairs of clusters are merged as one
moves up the hierarchy.</p></li>
<li><p>Divisive: This is a “top down” approach where all observations start
in one cluster, and splits are performed recursively as one moves
down the hierarchy.</p></li>
</ul>
<p><span class="math inline">\(\Omega\)</span> being the training set to classify and <span class="math inline">\(dist\)</span> a measure of
dissimilarity (metric) on this set, we define a distance <span class="math inline">\(LC\)</span> (linkage
criterion) between the parts of <span class="math inline">\(\Omega\)</span>. The agglomerative hierarchical
clustering algorithm is described in Algorithm 2.</p>
<p><img src="book_files/figure-html/algo_CAH-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div id="metric" class="section level4 unnumbered">
<h4>Metric</h4>
<p>The choice of an appropriate metric will influence the shape of the
clusters, as some clusters may be similar according to one distance or
farther away according to another. Given two sets of observations
<span class="math inline">\(A \subset \Omega\)</span> and <span class="math inline">\(B \subset \Omega\)</span> with <span class="math inline">\(i\)</span> the index of the
<span class="math inline">\(i^{th}\)</span> observation, the most commonly used metrics are:</p>
<ul>
<li><p>Euclidean distance: <span class="math inline">\(||A - B||_2 = \sqrt(\sum_i(A_i - B_i)^2)\)</span></p></li>
<li><p>Manhattan distance: <span class="math inline">\(||A - B||_1 = \sum_i |A_i - B_i|\)</span></p></li>
<li><p>Maximum distance:
<span class="math inline">\(||A - B||_{\infty} = \underset{i}{\text{max}} |A_i - B_i|\)</span></p></li>
</ul>
</div>
<div id="linkage-criteria" class="section level4 unnumbered">
<h4>Linkage criteria</h4>
<p>The linkage criterion determines the distance between sets of
observations as a function of the pairwise distances between
observations. Some commonly used linkage criteria between two sets of
observations <span class="math inline">\(A \subset \Omega\)</span> and <span class="math inline">\(B \subset \Omega\)</span> are:</p>
<ul>
<li><p>Single linkage: The dissimilarity between two sets is measured as
the minimum dissimilarity between the observations of the sets:
<span class="math display">\[LC(A,B) = \text{min} \lbrace dist(i,i&#39;), i \in A \text{ and } i&#39; \in B \rbrace\]</span></p></li>
<li><p>Complete linkage: The dissimilarity between two clusters is measured
as the maximum dissimilarity between the observations of the groups:
<span class="math display">\[LC(A,B) = \text{max} \lbrace dist(i,i&#39;), i \in A \text{ and } i&#39; \in B \rbrace\]</span></p></li>
<li><p>Average linkage: The dissimilarity between two clusters is measured
as the averaged dissimilarity between the observations of the
groups:
<span class="math display">\[LC(A,B) = \frac{\sum_{i \in A}\sum_{i&#39;\in B} dist(i,i&#39;)}{\text{card}(A).\text{card}(B)}\]</span></p></li>
</ul>
</div>
<div id="wards-method" class="section level4 unnumbered">
<h4>Ward’s method</h4>
<p>When the set <span class="math inline">\(\Omega \in \mathbb{R}^D\)</span> to classify is measured by <span class="math inline">\(D\)</span> variables
and where each element of <span class="math inline">\(\Omega\)</span> is represented by a vector <span class="math inline">\(\boldsymbol{x}\)</span>, we
could use the method developed by <span class="citation">(Ward <a href="#ref-ward_hierarchical_1963">1963</a>)</span> to construct
a hierarchy among these variables. We note
<span class="math inline">\(\mathcal{G} = \lbrace \mathcal{G}^1, \dots, \mathcal{G}^s, \dots, \mathcal{G}^S \rbrace\)</span>
the group partitions coming from the <span class="math inline">\(S\)</span> levels of the hierarchical
clustering performed on the matrix <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{n \times D}\)</span>.</p>
<p>Given <span class="math inline">\(\mathcal{G}^s= (\mathcal{G}^s_1, \dots, \mathcal{G}^s_g, \dots, \mathcal{G}^s_{G_s})\)</span> a
partition of <span class="math inline">\(\Omega\)</span> in <span class="math inline">\(G_s\)</span> groups at a particular level <span class="math inline">\(s\)</span> of the
hierarchy, the within-group inertia is defined as
<span class="math display">\[I_W (\mathcal{G}^s) = \sum_{g=1}^{G_s} \sum_{\boldsymbol{x} \in \mathcal{G}^s_g} dist^2(\boldsymbol{x}, \bar{\boldsymbol{x}}_g),\]</span>
where <span class="math inline">\(\bar{\boldsymbol{x}}_g\)</span> is the centroid of group <span class="math inline">\(\mathcal{G}^s_g\)</span>.</p>
<p>Equivalently we define the inter-group inertia as
<span class="math display">\[I_B(\mathcal{G}^s) = \sum_{g=1}^{G_s} \text{card}(\mathcal{G}^s_g) dist^2(\bar{\boldsymbol{x}}, \bar{\boldsymbol{x}}_g),\]</span>
where <span class="math inline">\(\bar{\boldsymbol{x}}\)</span> is the centroid of <span class="math inline">\(\Omega\)</span>.</p>
<p>It can be shown that the total inertia, at a given level <span class="math inline">\(s\)</span>, can be
decomposed as <span class="math display">\[I_s = I_W (\mathcal{G}^s) + I_B(\mathcal{G}^s).\]</span></p>
<p>A partition will then be all the more homogeneous as the within-group
inertia will be close to 0 and it can be shown that the fusion of two
groups necessarily increases the total inertia. It is then possible to
propose an agglomerative hierarchical clustering algorithm that fuse, at
each step, the two groups <span class="math inline">\(\mathcal{G}^s_g \in \mathcal{G}^s\)</span> and
<span class="math inline">\(\mathcal{G}^s_{g&#39;} \in \mathcal{G}^s\)</span> that minimize the Ward’s minimum variance
criterion:</p>
<p><span class="math display">\[LC( \mathcal{G}^s_g,  \mathcal{G}^s_{g&#39;}) = \frac{\text{card}( \mathcal{G}^s_g).\text{card}( \mathcal{G}^s_{g&#39;})}{\text{card}( \mathcal{G}^s_g) + \text{card}( \mathcal{G}^s_{g&#39;})} d^2(\bar{\boldsymbol{x}}_g, \bar{\boldsymbol{x}}_{g&#39;}),\]</span>
where <span class="math inline">\(\bar{\boldsymbol{x}}_g\)</span> and <span class="math inline">\(\bar{\boldsymbol{x}}_{g&#39;}\)</span> are the centroids of groups
<span class="math inline">\(\mathcal{G}^s_g\)</span> and <span class="math inline">\(\mathcal{G}^s_{g&#39;}\)</span> respectively.</p>
</div>
<div id="estimation-of-the-number-of-clusters" class="section level4 unnumbered">
<h4>Estimation of the number of clusters</h4>
<p>The choice of the number of groups in cluster analysis is often
ambiguous and depends on many parameters of the dataset. Several model
selection criteria have already been investigated to makes such a
decision
<span class="citation">(Tibshirani, Walther, and Hastie <a href="#ref-tibshirani_estimating_2001">2001</a>; Caliński and Harabasz <a href="#ref-calinski_dendrite_1974">1974</a>; Krzanowski and Lai <a href="#ref-krzanowski_criterion_1988">1988</a>)</span>.
These methods are based on the measure of within-group dispersion <span class="math inline">\(I_W\)</span>.</p>
<p>The gap statistic was developed by <span class="citation">(Tibshirani, Walther, and Hastie <a href="#ref-tibshirani_estimating_2001">2001</a>)</span> to find
a way to compare the distribution of <span class="math inline">\(\log I_W(\mathcal{G}^s)\)</span>,
<span class="math inline">\(\mathcal{G}^s = ( \mathcal{G}^s_1, \dots, \mathcal{G}^s_g, \dots, \mathcal{G}^s_{G_s})\)</span>,
with its expectation <span class="math inline">\(\mathbb{E}^*[\log I_W(\mathcal{G}^s)]\)</span> under a
reference distribution, i.e. a distribution with no obvious clustering.
The gap statistic for a given number of groups <span class="math inline">\(G_s\)</span> is then defined as
<span class="math display">\[\text{Gap}(G_s) = \mathbb{E}^*[\log I_W(\mathcal{G}^s)] - \log I_W(\mathcal{G}^s).\]</span></p>
<p>To obtain the estimate <span class="math inline">\(\mathbb{E}^*[\log I_W(\mathcal{G}^s)]\)</span>, <span class="math inline">\(B\)</span> copies
of <span class="math inline">\(\log I_W(\mathcal{G}^s)\)</span> are generated with a Monte Carlo sample drawn
from the reference distribution and averaged.</p>
<p>The gap statistic procedure to estimate the optimal number of groups
<span class="math inline">\(\hat{G}_s^*\)</span> can be summarized as follows.</p>
<p><strong>Step 1</strong> : Construct the hierarchy on <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{n \times D}\)</span>, varying the
total number of clusters from <span class="math inline">\(G = (G_1, \dots, G_S)\)</span> and compute
the within-group inertia <span class="math inline">\(I_W(\mathcal{G})\)</span> for each partition
<span class="math inline">\(\mathcal{G}= (\mathcal{G}^1,\dots,\mathcal{G}^s, \dots, \mathcal{G}^S)\)</span>.</p>
<p><strong>Step 2</strong> : Generate <span class="math inline">\(B\)</span> reference data sets from a uniform distribution over
the range of observed values and cluster each one giving
<span class="math inline">\(I_{W}^*(\mathcal{G}^b)\)</span> for each bootstrapped partition
<span class="math inline">\(\mathcal{G}^b= (\mathcal{G}^{b1},\dots,\mathcal{G}^{bs}, \dots, \mathcal{G}^{bS}), b = (1,\dots,B)\)</span>.
Compute the estimated gap statistic
<span class="math display">\[\text{Gap}(G_s) = \frac{1}{B} \sum_{b=1}^B \log I_W^*(\mathcal{G}^{bs}) - \log I_W(\mathcal{G}^s).\]</span></p>
<p><strong>Step 3</strong> : Compute the standard deviation
<span class="math display">\[sd(\mathcal{G}^s) = \sqrt{\frac{1}{B} \sum_{b=1}^B [\log I_W^*(\mathcal{G}^{bs}) - \bar{b}]^2},\]</span>
where <span class="math inline">\(\bar{b} = 1/B \sum_{b=1}^B \log I_W^*(\mathcal{G}^{bs})\)</span>, and
define <span class="math inline">\(SD_s = sd(\mathcal{G}^s) \sqrt{1 + 1/B}\)</span>.</p>
<p><strong>Step 4</strong> : Choose the estimated optimal number of clusters via
<span class="math display">\[\hat{G}_s^* = \text{smallest } G_s \text{ such that } \text{Gap}(G_s) \geq  \text{Gap}(G_{s+1}) - SD_{s+1}.\]</span></p>
</div>
</div>
<div id="HCAR" class="section level3">
<h3><span class="header-section-number">2.5.2</span> Hierarchical Clustering and Averaging Regression</h3>
<p>Hierarchical Clustering and Averaging Regression (HCAR) is a method
developed by <span class="citation">(Park, Hastie, and Tibshirani <a href="#ref-park_averaged_2007">2007</a>)</span> that combines hierarchical clustering
and penalized regression in the context of gene expression measurement.</p>
<p>The Algorithm 3 can be summarized as follows: At first a
hierarchical clustering is applied to the gene expression data to obtain
a dendrogram that reveals their nested correlation structure. At each
level of the hierarchy, a unique set of genes and supergenes is created
by computing the average expression of the current clusters. Then, the
different sets of genes and supergenes are used as inputs for a Lasso
regression.</p>
<p><img src="book_files/figure-html/algo_HCAR-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Hierarchical clustering proved to be especially adapted in this context
because it provides multiple levels at which the supergenes can be
formed. Due to the fact that the Euclidean distance measure among the
genes is a monotone function of their correlation (when the genes are
properly standardized), hierarchical clustering provides flexibility in
model selection in such a way that the genes are merged into supergenes
in order of their correlation.</p>
<p><span class="citation">(Park, Hastie, and Tibshirani <a href="#ref-park_averaged_2007">2007</a>)</span> proved that, in the presence of strong
collinearity among the predictors, an averaged predictor yields to an
estimate of the OLS coefficients with lower expected squared error than
the raw predictors. The authors claimed that this theorem could easily
be generalized to a block-diagonal correlation structure. The average
features within each block may yield a more accurate fit than the
individual predictors.</p>
</div>
<div id="MLGL" class="section level3">
<h3><span class="header-section-number">2.5.3</span> Multi-Layer Group-Lasso (MLGL)</h3>
<p><span class="citation">(Grimonprez <a href="#ref-grimonprez_selection_2016">2016</a>)</span> define the Multi-layer Group-Lasso (MLGL)
as a two-step procedure that combines a hierarchical clustering with a
Group-Lasso regression. It is a weighted version of the overlapping
Group-Lasso <span class="citation">(Jacob, Obozinski, and Vert <a href="#ref-jacob2009group">2009</a>)</span> which performs variable selection on
multiple group partitions defined by the hierarchical clustering. A
weight is attributed to each possible group identified at all levels of
the hierarchy. Such weighting scheme favours groups creating at the
origin of large gaps in the hierarchy.</p>
<p>We note
<span class="math inline">\(\mathcal{G} = \lbrace \mathcal{G}^1, \dots, \mathcal{G}^s, \dots, \mathcal{G}^S \rbrace\)</span>
the group partition coming from the <span class="math inline">\(s= 1, \dots, S\)</span> levels of the
hierarchical clustering performed on the matrix <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{n \times D}\)</span>.
<span class="math inline">\(\mathcal{G}^s = (\mathcal{G}_1^s, \dots,\mathcal{G}^s_{G_s})\)</span> is the group
partition at the level <span class="math inline">\(s\)</span> of the hierarchy and <span class="math inline">\(G_s\)</span> the total number
of groups at the current level.</p>
<p>A group-lasso procedure is then fitted on the concatenated matrix of all
group partition at all levels of the hierarchy
<span class="math display">\[\mathbf{X}_{\mathcal{G}} = \left[ \mathbf{X}^1_{\mathcal{G}^1}, \dots, \mathbf{X}^s_{\mathcal{G}^s}, \dots, \mathbf{X}^S_{\mathcal{G}^S} \right] \text{ where } \mathbf{X}^s_{\mathcal{G}^s} = \left[ \mathbf{X}^s_{\mathcal{G}_1^s},\dots, \mathbf{X}^s_{\mathcal{G}_{Gs}^s} \right].\]</span>
The Multi-Layer Group-Lasso solution is defined by:</p>
<p><span class="math display">\[\hat{\beta}^{MLGL} = \underset{\beta}{\text{argmin}} \left\lbrace \frac{1}{2} || \mathbf{y} - \mathbf{X}_{\mathcal{G}} \beta ||_2^2 + \lambda \sum_{s=1}^{S} \rho_s \sum_{g=1}^{G_s} \sqrt{\text{Card}(\mathcal{G}_g^s)} ||\boldsymbol{\beta}_{\mathcal{G}_g^s}||_2 \right\rbrace,
\label{eq:MLGL}\]</span></p>
<p>with <span class="math inline">\(\lambda \geqslant 0\)</span> the penalty parameter,
<span class="math inline">\(\mathcal{G}_g^s \in \mathcal{G}^s\)</span> the <span class="math inline">\(g^{th}\)</span> cluster coming from level <span class="math inline">\(s\)</span>
of the hierarchy. The parameter <span class="math inline">\(\rho_s\)</span> is a weight attributed to each
group <span class="math inline">\(\mathcal{G}_g^s\)</span> and its purpose is to quantify the level of
confidence in each level of the hierarchy. This weight is defined by:
<span class="math display">\[\rho_s = \frac{1}{\sqrt{l_s}}\]</span> with <span class="math inline">\(l_s = h_{s-1} - h_s\)</span> the length
of the gap between two successive levels of the hierarchy. Thus, the
weight <span class="math inline">\(\rho_s\)</span> is minimal when the length of the gap is maximal with
the consequence of less penalizing in the groups at the origin of large
gaps in the hierarchy.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-rokach2005clustering">
<p>Rokach, Lior, and Oded Maimon. 2005. “Clustering Methods.” In <em>Data Mining and Knowledge Discovery Handbook</em>, 321–52. Springer.</p>
</div>
<div id="ref-ward_hierarchical_1963">
<p>Ward, J. H. 1963. “Hierarchical Grouping to Optimize an Objective Function.” <em>Journal of the American Statistical Association</em> 58 (301): 236–44.</p>
</div>
<div id="ref-tibshirani_estimating_2001">
<p>Tibshirani, R., G. Walther, and T. Hastie. 2001. “Estimating the Number of Clusters in a Data Set via the Gap Statistic.” <em>Journal of the Royal Statistical Society: Series B</em> 63 (2): 411–23.</p>
</div>
<div id="ref-calinski_dendrite_1974">
<p>Caliński, T., and J. Harabasz. 1974. “A Dendrite Method for Cluster Analysis.” <em>Communications in Statistics</em> 3 (1): 1–27.</p>
</div>
<div id="ref-krzanowski_criterion_1988">
<p>Krzanowski, W. J., and Y. T. Lai. 1988. “A Criterion for Determining the Number of Groups in a Data Set Using Sum-of-Squares Clustering.” <em>Biometrics</em> 44 (1): 23–34.</p>
</div>
<div id="ref-park_averaged_2007">
<p>Park, Mee Young, Trevor Hastie, and Robert Tibshirani. 2007. “Averaged Gene Expressions for Regression.” <em>Biostatistics</em> 8 (2): 212–27.</p>
</div>
<div id="ref-grimonprez_selection_2016">
<p>Grimonprez, Quentin. 2016. “Selection de Groupes de Variables corrÃÂ©lÃÂ©es En Grande Dimension.” PhD thesis, Université de Lille; Lille 1.</p>
</div>
<div id="ref-jacob2009group">
<p>Jacob, Laurent, Guillaume Obozinski, and Jean-Philippe Vert. 2009. “Group LAsso with Overlap and Graph LAsso.” In <em>Proceedings of the 26th Annual International Conference on Machine Learning</em>, 433–40. Montreal, Quebec, Canada.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="non-parametric.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hypothesis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": ["book.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
