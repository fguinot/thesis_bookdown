<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>2.6 Statistical testing of significance | book.utf8.md</title>
  <meta name="description" content="PdD thesis">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="2.6 Statistical testing of significance | book.utf8.md />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="PdD thesis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.6 Statistical testing of significance | book.utf8.md />
  
  <meta name="twitter:description" content="PdD thesis" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="combining-cluster-analysis-and-variable-selection.html">
<link rel="next" href="asso.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical learning for omics association and interactions studies based on blockwise feature compression</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i>General introduction</a></li>
<li class="chapter" data-level="" data-path="notations.html"><a href="notations.html"><i class="fa fa-check"></i>Notations</a></li>
<li class="chapter" data-level="" data-path="abbreviations.html"><a href="abbreviations.html"><i class="fa fa-check"></i>Abbreviations</a></li>
<li class="chapter" data-level="1" data-path="genet.html"><a href="genet.html"><i class="fa fa-check"></i><b>1</b> Basic concepts of molecular genetics</a><ul>
<li class="chapter" data-level="1.1" data-path="genome.html"><a href="genome.html"><i class="fa fa-check"></i><b>1.1</b> Genome description</a></li>
<li class="chapter" data-level="1.2" data-path="genome-sequencing.html"><a href="genome-sequencing.html"><i class="fa fa-check"></i><b>1.2</b> Genome sequencing</a><ul>
<li class="chapter" data-level="1.2.1" data-path="genome-sequencing.html"><a href="genome-sequencing.html#DNAseq"><i class="fa fa-check"></i><b>1.2.1</b> DNA sequencing</a></li>
<li class="chapter" data-level="1.2.2" data-path="genome-sequencing.html"><a href="genome-sequencing.html#sequence-assembly"><i class="fa fa-check"></i><b>1.2.2</b> Sequence assembly</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html"><i class="fa fa-check"></i><b>1.3</b> DNA polymorphism</a><ul>
<li class="chapter" data-level="1.3.1" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html#restriction-fragment-length-polymorphisms-rflp"><i class="fa fa-check"></i><b>1.3.1</b> Restriction Fragment Length Polymorphisms (RFLP)</a></li>
<li class="chapter" data-level="1.3.2" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html#simple-sequence-length-polymorphisms-sslp"><i class="fa fa-check"></i><b>1.3.2</b> Simple Sequence Length Polymorphisms (SSLP)</a></li>
<li class="chapter" data-level="1.3.3" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html#single-nucleotide-polymorphisms-snp"><i class="fa fa-check"></i><b>1.3.3</b> Single Nucleotide Polymorphisms (SNP)</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="linkage.html"><a href="linkage.html"><i class="fa fa-check"></i><b>1.4</b> Linkage and partial linkage for genetic mapping</a></li>
<li class="chapter" data-level="1.5" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html"><i class="fa fa-check"></i><b>1.5</b> Basic concepts in population genetics</a><ul>
<li class="chapter" data-level="1.5.1" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html#HWE"><i class="fa fa-check"></i><b>1.5.1</b> Hardy-Weinberg equilibrium in large population</a></li>
<li class="chapter" data-level="1.5.2" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html#genetic-drift-in-small-population"><i class="fa fa-check"></i><b>1.5.2</b> Genetic drift in small population</a></li>
<li class="chapter" data-level="1.5.3" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html#concept-of-heritability"><i class="fa fa-check"></i><b>1.5.3</b> Concept of heritability</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="LD.html"><a href="LD.html"><i class="fa fa-check"></i><b>1.6</b> Linkage disequilibrium</a><ul>
<li class="chapter" data-level="1.6.1" data-path="LD.html"><a href="LD.html#definition"><i class="fa fa-check"></i><b>1.6.1</b> Definition</a></li>
<li class="chapter" data-level="1.6.2" data-path="LD.html"><a href="LD.html#measure-of-ld"><i class="fa fa-check"></i><b>1.6.2</b> Measure of LD</a></li>
<li class="chapter" data-level="1.6.3" data-path="LD.html"><a href="LD.html#estimation-of-linkage-disequilibrium"><i class="fa fa-check"></i><b>1.6.3</b> Estimation of linkage disequilibrium</a></li>
<li class="chapter" data-level="1.6.4" data-path="LD.html"><a href="LD.html#origins-of-linkage-disequilibrium"><i class="fa fa-check"></i><b>1.6.4</b> Origins of linkage disequilibrium</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="haplo.html"><a href="haplo.html"><i class="fa fa-check"></i><b>1.7</b> Structure of haplotype blocks in the human genome</a><ul>
<li class="chapter" data-level="" data-path="haplo.html"><a href="haplo.html#definition-of-haplotype-blocks"><i class="fa fa-check"></i>Definition of haplotype blocks</a></li>
<li class="chapter" data-level="" data-path="haplo.html"><a href="haplo.html#patterns-in-human-genome"><i class="fa fa-check"></i>Patterns in human genome</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="stat.html"><a href="stat.html"><i class="fa fa-check"></i><b>2</b> Statistical context</a><ul>
<li class="chapter" data-level="2.1" data-path="notations-1.html"><a href="notations-1.html"><i class="fa fa-check"></i><b>2.1</b> Notations</a></li>
<li class="chapter" data-level="2.2" data-path="concepts-of-statistical-learning.html"><a href="concepts-of-statistical-learning.html"><i class="fa fa-check"></i><b>2.2</b> Concepts of statistical learning</a><ul>
<li class="chapter" data-level="2.2.1" data-path="concepts-of-statistical-learning.html"><a href="concepts-of-statistical-learning.html#prediction"><i class="fa fa-check"></i><b>2.2.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="parametric.html"><a href="parametric.html"><i class="fa fa-check"></i><b>2.3</b> Parametric methods</a><ul>
<li class="chapter" data-level="2.3.1" data-path="parametric.html"><a href="parametric.html#linmod"><i class="fa fa-check"></i><b>2.3.1</b> Linear models</a></li>
<li class="chapter" data-level="2.3.2" data-path="parametric.html"><a href="parametric.html#penalized"><i class="fa fa-check"></i><b>2.3.2</b> Penalized linear regression</a></li>
<li class="chapter" data-level="2.3.3" data-path="parametric.html"><a href="parametric.html#glm"><i class="fa fa-check"></i><b>2.3.3</b> Generalized linear models</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="non-parametric.html"><a href="non-parametric.html"><i class="fa fa-check"></i><b>2.4</b> Splines and generalized additive models: Moving beyond linearit</a><ul>
<li class="chapter" data-level="2.4.1" data-path="non-parametric.html"><a href="non-parametric.html#introduction"><i class="fa fa-check"></i><b>2.4.1</b> Introduction</a></li>
<li class="chapter" data-level="2.4.2" data-path="non-parametric.html"><a href="non-parametric.html#splines"><i class="fa fa-check"></i><b>2.4.2</b> Regression splines</a></li>
<li class="chapter" data-level="2.4.3" data-path="non-parametric.html"><a href="non-parametric.html#mathrmb-splines"><i class="fa fa-check"></i><b>2.4.3</b> <span class="math inline">\(\mathrm{B}\)</span>-splines</a></li>
<li class="chapter" data-level="2.4.4" data-path="non-parametric.html"><a href="non-parametric.html#smoothing"><i class="fa fa-check"></i><b>2.4.4</b> Cubic smoothing splines</a></li>
<li class="chapter" data-level="2.4.5" data-path="non-parametric.html"><a href="non-parametric.html#gam"><i class="fa fa-check"></i><b>2.4.5</b> Generalized additive models (GAM)</a></li>
<li class="chapter" data-level="2.4.6" data-path="non-parametric.html"><a href="non-parametric.html#hgam"><i class="fa fa-check"></i><b>2.4.6</b> High-dimensional generalized additive models (HGAM)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html"><i class="fa fa-check"></i><b>2.5</b> Combining cluster analysis and variable selection</a><ul>
<li class="chapter" data-level="2.5.1" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html#CAH"><i class="fa fa-check"></i><b>2.5.1</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="2.5.2" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html#HCAR"><i class="fa fa-check"></i><b>2.5.2</b> Hierarchical Clustering and Averaging Regression</a></li>
<li class="chapter" data-level="2.5.3" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html#MLGL"><i class="fa fa-check"></i><b>2.5.3</b> Multi-Layer Group-Lasso (MLGL)</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="hypothesis.html"><a href="hypothesis.html"><i class="fa fa-check"></i><b>2.6</b> Statistical testing of significance</a><ul>
<li class="chapter" data-level="2.6.1" data-path="hypothesis.html"><a href="hypothesis.html#introduction-1"><i class="fa fa-check"></i><b>2.6.1</b> Introduction</a></li>
<li class="chapter" data-level="2.6.2" data-path="hypothesis.html"><a href="hypothesis.html#chi2"><i class="fa fa-check"></i><b>2.6.2</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="2.6.3" data-path="hypothesis.html"><a href="hypothesis.html#LRT"><i class="fa fa-check"></i><b>2.6.3</b> Likelihood ratio test</a></li>
<li class="chapter" data-level="2.6.4" data-path="hypothesis.html"><a href="hypothesis.html#pvalGAM"><i class="fa fa-check"></i><b>2.6.4</b> Calculation of <em>p</em>-values in GAM</a></li>
<li class="chapter" data-level="2.6.5" data-path="hypothesis.html"><a href="hypothesis.html#multiple"><i class="fa fa-check"></i><b>2.6.5</b> Multiple testing comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="asso.html"><a href="asso.html"><i class="fa fa-check"></i><b>3</b> Genome-Wide Association Studies</a><ul>
<li class="chapter" data-level="3.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="genoquality.html"><a href="genoquality.html"><i class="fa fa-check"></i><b>3.2</b> Genotype quality control</a><ul>
<li class="chapter" data-level="3.2.1" data-path="genoquality.html"><a href="genoquality.html#deviation-from-hwe."><i class="fa fa-check"></i><b>3.2.1</b> Deviation from HWE.</a></li>
<li class="chapter" data-level="3.2.2" data-path="genoquality.html"><a href="genoquality.html#missing-data."><i class="fa fa-check"></i><b>3.2.2</b> Missing data.</a></li>
<li class="chapter" data-level="3.2.3" data-path="genoquality.html"><a href="genoquality.html#distribution-of-test-statistics."><i class="fa fa-check"></i><b>3.2.3</b> Distribution of test statistics.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="OR.html"><a href="OR.html"><i class="fa fa-check"></i><b>3.3</b> Disease penetrance and odds ratio</a></li>
<li class="chapter" data-level="3.4" data-path="SMA.html"><a href="SMA.html"><i class="fa fa-check"></i><b>3.4</b> Single Marker Analysis</a><ul>
<li class="chapter" data-level="3.4.1" data-path="SMA.html"><a href="SMA.html#pearsons-chi2-statistic"><i class="fa fa-check"></i><b>3.4.1</b> Pearson’s <span class="math inline">\(\chi^2\)</span> statistic</a></li>
<li class="chapter" data-level="3.4.2" data-path="SMA.html"><a href="SMA.html#cochran-armitage-trend-test"><i class="fa fa-check"></i><b>3.4.2</b> Cochran-Armitage trend test</a></li>
<li class="chapter" data-level="3.4.3" data-path="SMA.html"><a href="SMA.html#logitGWAS"><i class="fa fa-check"></i><b>3.4.3</b> Logistic regression and likelihood ratio test</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="GWASlimits.html"><a href="GWASlimits.html"><i class="fa fa-check"></i><b>3.5</b> Limitations</a></li>
<li class="chapter" data-level="3.6" data-path="popstructure.html"><a href="popstructure.html"><i class="fa fa-check"></i><b>3.6</b> Population structure</a><ul>
<li class="chapter" data-level="3.6.1" data-path="popstructure.html"><a href="popstructure.html#genomic-control"><i class="fa fa-check"></i><b>3.6.1</b> Genomic control</a></li>
<li class="chapter" data-level="3.6.2" data-path="popstructure.html"><a href="popstructure.html#structured-association"><i class="fa fa-check"></i><b>3.6.2</b> Structured association</a></li>
<li class="chapter" data-level="3.6.3" data-path="popstructure.html"><a href="popstructure.html#PCC"><i class="fa fa-check"></i><b>3.6.3</b> Principle components correction</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="multiloc.html"><a href="multiloc.html"><i class="fa fa-check"></i><b>3.7</b> Multi-locus analysis</a><ul>
<li class="chapter" data-level="3.7.1" data-path="multiloc.html"><a href="multiloc.html#haplotype-based-approaches"><i class="fa fa-check"></i><b>3.7.1</b> Haplotype-based approaches</a></li>
<li class="chapter" data-level="3.7.2" data-path="multiloc.html"><a href="multiloc.html#rare-variant"><i class="fa fa-check"></i><b>3.7.2</b> Rare-variant association analysis</a></li>
<li class="chapter" data-level="3.7.3" data-path="multiloc.html"><a href="multiloc.html#adjclust"><i class="fa fa-check"></i><b>3.7.3</b> LD based approach to variable selection in GWAS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="LEOS.html"><a href="LEOS.html"><i class="fa fa-check"></i><b>4</b> Learning the Optimal in GWAS through hierarchical SNP aggregation</a><ul>
<li class="chapter" data-level="4.1" data-path="introleos.html"><a href="introleos.html"><i class="fa fa-check"></i><b>4.1</b> Related work</a></li>
<li class="chapter" data-level="4.2" data-path="leosmethod.html"><a href="leosmethod.html"><i class="fa fa-check"></i><b>4.2</b> Method</a><ul>
<li class="chapter" data-level="4.2.1" data-path="leosmethod.html"><a href="leosmethod.html#CHAC"><i class="fa fa-check"></i><b>4.2.1</b> Step 1. Constrained-HAC</a></li>
<li class="chapter" data-level="4.2.2" data-path="leosmethod.html"><a href="leosmethod.html#Dstar"><i class="fa fa-check"></i><b>4.2.2</b> Step 2. Dimension reduction function</a></li>
<li class="chapter" data-level="4.2.3" data-path="leosmethod.html"><a href="leosmethod.html#cutree"><i class="fa fa-check"></i><b>4.2.3</b> Step 3. Optimal number of groups estimation</a></li>
<li class="chapter" data-level="4.2.4" data-path="leosmethod.html"><a href="leosmethod.html#step4"><i class="fa fa-check"></i><b>4.2.4</b> Step 4. Multiple testing on aggregated-SNP variables</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="numsim.html"><a href="numsim.html"><i class="fa fa-check"></i><b>4.3</b> Numerical simulations</a><ul>
<li class="chapter" data-level="4.3.1" data-path="numsim.html"><a href="numsim.html#simupheno"><i class="fa fa-check"></i><b>4.3.1</b> Simulation of the case-control phenotype</a></li>
<li class="chapter" data-level="4.3.2" data-path="numsim.html"><a href="numsim.html#perfeval"><i class="fa fa-check"></i><b>4.3.2</b> Performance evaluation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>4.4</b> Results</a><ul>
<li class="chapter" data-level="4.4.1" data-path="results.html"><a href="results.html#results-and-discussions-of-the-numerical-simulations"><i class="fa fa-check"></i><b>4.4.1</b> Results and discussions of the numerical simulations</a></li>
<li class="chapter" data-level="4.4.2" data-path="results.html"><a href="results.html#performance-results-for-simulated-data."><i class="fa fa-check"></i><b>4.4.2</b> Performance results for simulated data.</a></li>
<li class="chapter" data-level="4.4.3" data-path="results.html"><a href="results.html#leosappli"><i class="fa fa-check"></i><b>4.4.3</b> Application in Wellcome Trust Case Control Consortium(WTCCC) and Ankylosing Spondylitis (AS) studies</a></li>
<li class="chapter" data-level="4.4.4" data-path="results.html"><a href="results.html#realdata"><i class="fa fa-check"></i><b>4.4.4</b> Results in WTCCC and AS studies</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="leosgam.html"><a href="leosgam.html"><i class="fa fa-check"></i><b>4.5</b> Generalized additive models in GWAS</a><ul>
<li class="chapter" data-level="4.5.1" data-path="leosgam.html"><a href="leosgam.html#comparison-of-predictive-power"><i class="fa fa-check"></i><b>4.5.1</b> Comparison of predictive power</a></li>
<li class="chapter" data-level="4.5.2" data-path="leosgam.html"><a href="leosgam.html#results-of-univariate-smoothing-splines-on-aggregated-snp"><i class="fa fa-check"></i><b>4.5.2</b> Results of univariate smoothing splines on aggregated-SNP</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="discussions.html"><a href="discussions.html"><i class="fa fa-check"></i><b>4.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sicomore.html"><a href="sicomore.html"><i class="fa fa-check"></i><b>5</b> Selection of interaction effects in compressed multiple omics representation</a><ul>
<li class="chapter" data-level="5.1" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a><ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-3.html"><a href="introduction-3.html#background-1"><i class="fa fa-check"></i><b>5.1.1</b> Background</a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-3.html"><a href="introduction-3.html#combining-genome-and-metagenome-analyses."><i class="fa fa-check"></i><b>5.1.2</b> Combining genome and metagenome analyses.</a></li>
<li class="chapter" data-level="5.1.3" data-path="introduction-3.html"><a href="introduction-3.html#taking-structures-into-account-in-association-studies."><i class="fa fa-check"></i><b>5.1.3</b> Taking structures into account in association studies.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="modelsicomore.html"><a href="modelsicomore.html"><i class="fa fa-check"></i><b>5.2</b> Learning with complementary datasets</a><ul>
<li class="chapter" data-level="5.2.1" data-path="modelsicomore.html"><a href="modelsicomore.html#setting-and-notations"><i class="fa fa-check"></i><b>5.2.1</b> Setting and notations</a></li>
<li class="chapter" data-level="5.2.2" data-path="modelsicomore.html"><a href="modelsicomore.html#interactions-in-linear-models"><i class="fa fa-check"></i><b>5.2.2</b> Interactions in linear models</a></li>
<li class="chapter" data-level="5.2.3" data-path="modelsicomore.html"><a href="modelsicomore.html#compressdata"><i class="fa fa-check"></i><b>5.2.3</b> Compact model</a></li>
<li class="chapter" data-level="5.2.4" data-path="modelsicomore.html"><a href="modelsicomore.html#recoverinteractions"><i class="fa fa-check"></i><b>5.2.4</b> Recovering relevant interactions</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="implementation.html"><a href="implementation.html"><i class="fa fa-check"></i><b>5.3</b> Method</a><ul>
<li class="chapter" data-level="5.3.1" data-path="implementation.html"><a href="implementation.html#preprocess"><i class="fa fa-check"></i><b>5.3.1</b> Preprocessing of the data</a></li>
<li class="chapter" data-level="5.3.2" data-path="implementation.html"><a href="implementation.html#preprocessing-of-metagenomic-data"><i class="fa fa-check"></i><b>5.3.2</b> Preprocessing of metagenomic data</a></li>
<li class="chapter" data-level="5.3.3" data-path="implementation.html"><a href="implementation.html#structure"><i class="fa fa-check"></i><b>5.3.3</b> Structuring the data</a></li>
<li class="chapter" data-level="5.3.4" data-path="implementation.html"><a href="implementation.html#using-the-structure-efficiently"><i class="fa fa-check"></i><b>5.3.4</b> Using the structure efficiently</a></li>
<li class="chapter" data-level="5.3.5" data-path="implementation.html"><a href="implementation.html#identification-of-relevant-supervariables"><i class="fa fa-check"></i><b>5.3.5</b> Identification of relevant supervariables</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="XPsimu.html"><a href="XPsimu.html"><i class="fa fa-check"></i><b>5.4</b> Numerical simulations</a><ul>
<li class="chapter" data-level="5.4.1" data-path="XPsimu.html"><a href="XPsimu.html#data-generation"><i class="fa fa-check"></i><b>5.4.1</b> Data generation</a></li>
<li class="chapter" data-level="5.4.2" data-path="XPsimu.html"><a href="XPsimu.html#generation-of-the-phenotype"><i class="fa fa-check"></i><b>5.4.2</b> Generation of the phenotype</a></li>
<li class="chapter" data-level="5.4.3" data-path="XPsimu.html"><a href="XPsimu.html#comparison-of-methods"><i class="fa fa-check"></i><b>5.4.3</b> Comparison of methods</a></li>
<li class="chapter" data-level="5.4.4" data-path="XPsimu.html"><a href="XPsimu.html#evaluation-metrics"><i class="fa fa-check"></i><b>5.4.4</b> Evaluation metrics</a></li>
<li class="chapter" data-level="5.4.5" data-path="XPsimu.html"><a href="XPsimu.html#performance-results"><i class="fa fa-check"></i><b>5.4.5</b> Performance results</a></li>
<li class="chapter" data-level="5.4.6" data-path="XPsimu.html"><a href="XPsimu.html#computational-time"><i class="fa fa-check"></i><b>5.4.6</b> Computational time</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="XPINRA.html"><a href="XPINRA.html"><i class="fa fa-check"></i><b>5.5</b> Application on real data: rhizosphere of <em>Medicago truncatula</em></a><ul>
<li class="chapter" data-level="5.5.1" data-path="XPINRA.html"><a href="XPINRA.html#material"><i class="fa fa-check"></i><b>5.5.1</b> Material</a></li>
<li class="chapter" data-level="5.5.2" data-path="XPINRA.html"><a href="XPINRA.html#analysis"><i class="fa fa-check"></i><b>5.5.2</b> Analysis</a></li>
<li class="chapter" data-level="5.5.3" data-path="XPINRA.html"><a href="XPINRA.html#results-1"><i class="fa fa-check"></i><b>5.5.3</b> Results</a></li>
<li class="chapter" data-level="5.5.4" data-path="XPINRA.html"><a href="XPINRA.html#results-on-root-shoot-ratio"><i class="fa fa-check"></i><b>5.5.4</b> Results on Root Shoot Ratio</a></li>
<li class="chapter" data-level="5.5.5" data-path="XPINRA.html"><a href="XPINRA.html#results-on-specific-nitrogen-uptake"><i class="fa fa-check"></i><b>5.5.5</b> Results on Specific Nitrogen Uptake</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="discussions-1.html"><a href="discussions-1.html"><i class="fa fa-check"></i><b>5.6</b> Discussions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i>Conclusions</a><ul>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html#discussions-on-leos-algorithm"><i class="fa fa-check"></i>Discussions on LEOS algorithm</a></li>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html#discussions-on-sicomore-algorithm"><i class="fa fa-check"></i>Discussions on SICOMORE algorithm</a></li>
<li class="chapter" data-level="" data-path="perspectives.html"><a href="perspectives.html"><i class="fa fa-check"></i>Perspectives</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="annexes.html"><a href="annexes.html"><i class="fa fa-check"></i>Annexes</a><ul>
<li class="chapter" data-level="" data-path="biasvar.html"><a href="biasvar.html"><i class="fa fa-check"></i>Derivation of the MSE bias-variance decomposition</a></li>
<li class="chapter" data-level="" data-path="computational-aspect-of-splines-calculation.html"><a href="computational-aspect-of-splines-calculation.html"><i class="fa fa-check"></i>Computational aspect of splines calculation</a><ul>
<li><a href="computational-aspect-of-splines-calculation.html#linsmooth">Linear smoother <span class="citation">(Buja, Hastie, and Tibshirani <span>1989</span>)</span></a></li>
<li><a href="computational-aspect-of-splines-calculation.html#lambdasmooth">Smoothing parameter <span class="math inline">\(\lambda\)</span> for smoothing splines</a></li>
<li><a href="computational-aspect-of-splines-calculation.html#Bspline"><span class="math inline">\(\mathit{B}\)</span>-spline basis</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis" class="section level2">
<h2><span class="header-section-number">2.6</span> Statistical testing of significance</h2>
<div id="introduction-1" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Introduction</h3>
<p>In statistical hypothesis testing, statistical significance refers to
the acceptance or reject of the null hypothesis and corresponds to the
likelihood that the difference between a given variation and the
baseline is not due to random chance. For a given study, the defined
level of significance <span class="math inline">\(\alpha\)</span> is the probability to reject the true
null hypothesis and the <em>p</em>-value, <span class="math inline">\(p\)</span>, is the probability of obtaining
a result at least as extreme given that <span class="math inline">\(H_0\)</span> is true. We can therefore
state that the result is statistically significant, by the standard of
the study, if <span class="math inline">\(p &lt; \alpha\)</span>.</p>
<p>Ronald Fisher first advanced the idea of statistical hypothesis testing
in his famous publication <em>Statistical Methods for Research Workers</em>
<span class="citation">(Fisher <a href="#ref-fisher1935statistical">1935</a>)</span>. He suggested a probability of <span class="math inline">\(5\%\)</span> has an
acceptable threshold level to reject the null hypothesis and this
cut-off was later taken over by Jezzy Neyman and Egon Pearson in
<span class="citation">(Neyman and Pearson <a href="#ref-neyman1933testing">1933</a>)</span> where they named it the significance level
<span class="math inline">\(\alpha\)</span>.</p>
<p>They proposed the following hypothesis testing procedure:</p>
<ol style="list-style-type: lower-alpha">
<li>Before getting the experimental measures:</li>
</ol>
<ul>
<li><p>Define the null hypothesis <span class="math inline">\(H_0\)</span> and the alternative hypothesis
<span class="math inline">\(H_1\)</span>.</p></li>
<li><p>Choose a level <span class="math inline">\(\alpha\)</span>.</p></li>
<li><p>Choose a test statistic, <span class="math inline">\(T\)</span>, which is larger under <span class="math inline">\(H_1\)</span> than under <span class="math inline">\(H_0\)</span>: <span class="math display">\[\text{Reject } H_0 \Leftrightarrow  T \geq u.\]</span></p></li>
<li><p>Study the distribution of <span class="math inline">\(T\)</span> under <span class="math inline">\(H_0\)</span> and set the following condition:</p></li>
</ul>
<p><span class="math display">\[\mathbb{P}(T \geq u) \leq \alpha .\]</span></p>
<ul>
<li><p>Deduce the threshold <span class="math inline">\(u\)</span>.</p></li>
<li><p>Give the test with the value retained for <span class="math inline">\(u\)</span> and the real level:</p></li>
</ul>
<p><span class="math display">\[ \text{Reject } H_0 \Leftrightarrow  T \geq u .\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Once the measures are done:</li>
</ol>
<ul>
<li>Perform the numerical application and conclude if we accept or reject <span class="math inline">\(H_0\)</span> based on the <span class="math inline">\(p\text{-value} = \mathbb{P}(T \geq t_{obs})\)</span>.</li>
</ul>
<p>with</p>
<ul>
<li><p>Type I error: <span class="math inline">\(\alpha = \mathbb{P}\)</span> (accept <span class="math inline">\(H_1\)</span>, <span class="math inline">\(H_0\)</span> is true),</p></li>
<li><p>Type II error: <span class="math inline">\(\beta = \mathbb{P}\)</span> (accept <span class="math inline">\(H_0\)</span>, <span class="math inline">\(H_1\)</span> is true),</p></li>
<li><p>Power of the test: <span class="math inline">\(1 - \beta = \mathbb{P}\)</span> (accept <span class="math inline">\(H_1\)</span>, <span class="math inline">\(H_1\)</span> is true).</p></li>
</ul>
<p>and the confusion matrix defined in Table <a href="hypothesis.html#tab:confusion">2.1</a>.</p>
<table>
<caption><span id="tab:confusion">Table 2.1: </span>Confusion matrix</caption>
<tbody>
<tr class="odd">
<td></td>
<td align="left"><span class="math inline">\(H_0\)</span> true</td>
<td align="left"><span class="math inline">\(H_1\)</span> true</td>
</tr>
<tr class="even">
<td><span class="math inline">\(H_0\)</span> accepted</td>
<td align="left">True Positive</td>
<td align="left">False Positive</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(H_1\)</span> accepted</td>
<td align="left">False Negative</td>
<td align="left">True Negative</td>
</tr>
</tbody>
</table>
</div>
<div id="chi2" class="section level3">
<h3><span class="header-section-number">2.6.2</span> <span class="math inline">\(\chi^2\)</span> test</h3>
<p>The chi-squared test, also written as <span class="math inline">\(\chi^2\)</span> test, is a statistical
hypothesis test developed by Karl Pearson and first published in
<span class="citation">(Pearson <a href="#ref-pearson1900on">1900</a>)</span>. It is used when the sampling distribution of the test
statistic under the null hypothesis follows a chi-squared distribution.</p>
<p>The <span class="math inline">\(\chi^2\)</span> distribution with k degrees of freedom is the distribution
of a sum of the squares of <span class="math inline">\(D\)</span> independent standard normal random
variables. If <span class="math inline">\(\mathrm{X}_1, ..., \mathrm{X}_D\)</span> are independent, normally distributed
random variables, then the sum of their squares:
<span class="math display">\[Z =\sum _{d=1}^{D} \mathrm{X}_d^2,\]</span> is distributed according to the <span class="math inline">\(\chi^2\)</span>
distribution with <span class="math inline">\(D\)</span> degrees of freedom. This is usually denoted as
<span class="math inline">\(Z \sim \chi^{2}(D)\)</span> or <span class="math inline">\(Z \sim \chi_D^2\)</span>. The chi-squared distribution
has one parameter: <span class="math inline">\(D\)</span> — a positive integer that specifies the number of
degrees of freedom.</p>
<p>The chi-squared test is used to determine whether there is a significant
difference between the expected frequencies and the observed frequencies
in one or more categories. Test statistics that follow a chi-squared
distribution arise from an assumption of independent normally
distributed data, which is valid in many cases due to the central limit
theorem.</p>
</div>
<div id="LRT" class="section level3">
<h3><span class="header-section-number">2.6.3</span> Likelihood ratio test</h3>
<p>The likelihood ratio test is used for comparing the goodness of fit of
two statistical models, a null model against an alternative model. The
log-likelihood ratio statistic is generally used to compute a <em>p</em>-value
to decide whether or not to reject the null model.</p>
<p>Given the null <span class="math inline">\(H_0 : \theta = \theta_0\)</span> and the alternative hypothesis
<span class="math inline">\(H_1 = \theta = \theta_1\)</span> for a statistical model <span class="math inline">\(f(\boldsymbol{x}|\theta)\)</span>, the
likelihood ratio is defined as</p>
<p><span class="math display">\[\Lambda(\boldsymbol{x}) = \frac{l(\theta_0 | \boldsymbol{x})}{l(\theta_1 | \boldsymbol{x})},\]</span> where
<span class="math inline">\(\theta \mapsto l(\theta|\boldsymbol{x})\)</span> is the likelihood function and with
<span class="math inline">\(\alpha = \mathbb{P}(\Lambda(\boldsymbol{x}) \leq u | H_0)\)</span> the significance level
at a threshold <span class="math inline">\(u\)</span>.</p>
<p>In practice we define the test statistic as <span class="math display">\[\begin{aligned}
T &amp; = -2 \log \left( \frac{l(\theta_0 | \boldsymbol{x})}{l(\theta_1 | \boldsymbol{x})} \right) \\
&amp; = 2 \times [\log(l(\theta_1 | \boldsymbol{x})) - \log(l(\theta_0 | \boldsymbol{x}))]\end{aligned}\]</span></p>
<p>The Neyman-Pearson lemma introduced in <span class="citation">(Neyman and Pearson <a href="#ref-neyman1933testing">1933</a>)</span> states that
the likelihood ratio test is the most powerful test at a significance
level <span class="math inline">\(\alpha\)</span>.</p>
</div>
<div id="pvalGAM" class="section level3">
<h3><span class="header-section-number">2.6.4</span> Calculation of <em>p</em>-values in GAM</h3>
<p>Let <span class="math inline">\(\boldsymbol{\beta}^j \in \mathbb{R}^K\)</span> be the coefficients vector of the <span class="math inline">\(k\)</span>
covariates for a single smooth term <span class="math inline">\(j\)</span> and <span class="math inline">\(\mathbf{V}_{\boldsymbol{\beta}_j}\)</span> the
covariance matrix of <span class="math inline">\(\boldsymbol{\beta}_j\)</span>. In the context of generalized additive
models, if the covariates of the smooth are uncorrelated with other
smooth terms in the model, then <span class="math inline">\(\mathbb{E}(\hat{\boldsymbol{\beta}_j}) = 0\)</span>,
otherwise there is little bias and
<span class="math inline">\(\mathbb{E}(\hat{\boldsymbol{\beta}_j}) \simeq 0\)</span>.</p>
<p>Under the null hypothesis <span class="math inline">\(H_0: \boldsymbol{\beta}_j = 0\)</span> we have
<span class="math display">\[\hat{\boldsymbol{\beta}_j} \thicksim \mathcal{N}(0, \mathbf{V}_{\boldsymbol{\beta}_j}).\]</span></p>
<p>It follows that if <span class="math inline">\(\mathbf{V}_{\boldsymbol{\beta}_j}\)</span> is of full rank, then under the null
hypothesis</p>
<p><span class="math display">\[\hat{\boldsymbol{\beta}_j}^T \mathbf{V}_{\boldsymbol{\beta}_j}^{-1} \hat{\boldsymbol{\beta}_j} \thicksim \chi^2_k.\]</span></p>
<p>However, applying a penalty on the coefficients of the smooth, as it is
the case with smoothing splines, often suppress some dimensions of the
parameter space and consequently the covariance matrix <span class="math inline">\(\mathbf{V}_{\boldsymbol{\beta}_j}\)</span>
is not of full rank. If so, the test is performed using the rank
<span class="math inline">\(r = rank(\mathbf{V}_{\boldsymbol{\beta}_j})\)</span> pseudo-inverse of the covariance matrix
<span class="math inline">\(\mathbf{V}_{\boldsymbol{\beta}_j}^{r-}\)</span> and under the null,
<span class="math display">\[\hat{\boldsymbol{\beta}_j}^T \mathbf{V}_{\boldsymbol{\beta}_j}^{-r} \hat{\boldsymbol{\beta}_j} \thicksim \chi^2_r.\]</span></p>
<p>As stated in <span class="citation">(Wood <a href="#ref-wood_generalized_2006">2006</a>)</span>, as long as the <em>p</em>-values give a
clear cut result it is usually safe to rely on them, but when they are
close to the threshold of accepting or rejecting the null, they must be
carefully treated. Indeed, as the uncertainty on the smoothing parameter
estimation has been neglected in the reference distribution used for
testing, these distributions are typically too narrow and attribute too
low a probability to moderately high values in the test statistics. In
that case, to obtain more accurate <em>p</em>-values, it may be preferable to
perform test on overspecified unpenalized models even if it induces a
cost in terms of statistical power.</p>
</div>
<div id="multiple" class="section level3">
<h3><span class="header-section-number">2.6.5</span> Multiple testing comparison</h3>
<p>In some context, as it is the case with the analysis of genes expression
data or in Genome-Wide Association Studies (GWASs) for instance, we may
need to perform simultaneously a very large number, <span class="math inline">\(d \in [1,\dots,D]\)</span>,
of tests and therefore the same large number of <em>p</em>-value. If we reject,
for the <span class="math inline">\(d^{th}\)</span> tests, the null hypothesis <span class="math inline">\(H_{0,d}\)</span> when its
associated <em>p</em>-value <span class="math inline">\(\hat{p}_d\)</span> is not larger than <span class="math inline">\(\alpha\)</span>, then for
each tests <span class="math inline">\(d\)</span>, the probability to reject wrongly <span class="math inline">\(H_{0,d}\)</span> is at most
<span class="math inline">\(\alpha\)</span>. Nevertheless, if we consider the <span class="math inline">\(D\)</span> tests simultaneously the
number of hypothesis <span class="math inline">\(H_{0,d}\)</span> wrongly rejected (false positive or type
I error) can be very large. Actually, the expectation of the number of
false positives in given by:</p>
<p><span class="math display">\[\mathbb{E}[\text{False Positives}] = \sum_{d:H{0,d}}^D \mathbb{P}_{H{0,d}}(T_d \geq u_{\alpha}) = \text{card} \lbrace d:H_{0,d} \text{ is true} \rbrace\times \alpha,\]</span>
if the threshold <span class="math inline">\(u_{\alpha}\)</span> is such that <span class="math inline">\(\mathbb{P}_{H{0,d}} = \alpha\)</span>for every <span class="math inline">\(d\)</span>. For instance, for a typical value of <span class="math inline">\(\alpha = 5 \%\)</span> and card <span class="math inline">\(\lbrace d:H_{0,d} \text{ is true} \rbrace =1000\)</span>, then we obtain on
average 500 false positives. It is therefore necessary to adjust the
threshold <span class="math inline">\(u_{\alpha}\)</span> at which we reject the null hypothesis in order
to control for the number of false positives while not losing too much
power.</p>
<div id="controlling-the-family-wise-error-rate" class="section level4 unnumbered">
<h4>Controlling the Family-Wise Error Rate</h4>
<p>There exist many adjustments methods for multiple testing, including
controls of the Family-Wise Error Rate (FWER), i.e. the probability of
rejecting <span class="math inline">\(H_0\)</span> when it is true at least one time, noted as
<span class="math display">\[\text{FWER} = \mathbb{P}(\text{card(False Positives)} \geq 1).\]</span></p>
<ul>
<li>Bonferroni procedure:</li>
</ul>
<p>The most commonly used method for controlling the FWER is the
Bonferroni method <span class="citation">(Bonferroni <a href="#ref-bonferroni1936teoria">1936</a>)</span>. The test of each <span class="math inline">\(H_d\)</span> is
controlled so that the probability of a Type I error is less than or
equal to <span class="math inline">\(\alpha/D\)</span>, ensuring that the overall FWER is less than to
a given <span class="math inline">\(\alpha\)</span>.</p>
<ul>
<li><span>Š</span>id<span>á</span>k method:</li>
</ul>
<p>The method of <span class="citation">(Šidák <a href="#ref-sidak1967rectangular">1967</a>)</span> is closely related to
Bonferroni’s procedure where the <em>p</em>-value are adjusted as:
<span class="math display">\[p_d^{adj} = 1 - (1-p_d)^D,\]</span> where <span class="math inline">\(p_d\)</span> is the unadjusted p-value
for the <span class="math inline">\(d^{th}\)</span> test.</p>
<ul>
<li>Holm method:</li>
</ul>
<p>A less conservative adjustment method is the <span class="citation">(Holm <a href="#ref-holm1979simple">1979</a><a href="#ref-holm1979simple">a</a>)</span>
method that orders the <em>p</em>-values and makes successively smaller
adjustments. Let the ordered <em>p</em>-values be denoted by
<span class="math inline">\(p_{1} \leq p_{2} \leq \dots \leq p_{D}\)</span>. Then, the Holm method
calculates the adjusted <em>p</em>-values by <span class="math display">\[\begin{aligned}
    &amp; p_{1}^{adj} = D \times p_{1}, &amp; \nonumber\\
    &amp; p_{1}^{adj} = \text{max} \lbrace p_{d-1},(D-d+1) \times p_{d} \rbrace \ 1 \leq d \leq D.&amp;\end{aligned}\]</span></p>
<p>The principal issue with these approaches is that they control the
probability of at least one false positive regardless of the number of
hypothesis being tested. They reduce the number of type I error but
tends to be very conservative in the sense that the number of type II
error is increased resulting in a loss of power. That is why less
conservative methods are preferred in high-dimensional settings.</p>
</div>
<div id="BH" class="section level4 unnumbered">
<h4>Controlling the False Discovery Rate</h4>
<p>The False Discovery Proportion (FDP) corresponds to the proportion of
false positives among the positive FP/(FP+TP). The False Discovery Rate,
introduced in the seminal paper of <span class="citation">(BH, Benjamini and Hochberg <a href="#ref-benjamini_controlling_1995">1995</a>)</span>, is
defined as the expected value of the FDP:</p>
<p><span class="math display">\[\text{FDR} = \mathbb{E} \left[ \frac{\text{FP}}{\text{FP+TP}} \mathbb{1}_{\text{FP+TP} \geq 1} \right]. 
\label{eq:FDR}\]</span></p>
<p>Controlling the FDR quantity offers a less conservative multiple-testing
criterion than the FWER control. <span class="citation">(Benjamini and Hochberg <a href="#ref-benjamini_controlling_1995">1995</a>)</span> proved
that their approach, referred as the BH procedure, control the FDR at
level <span class="math inline">\(\alpha\)</span> under the condition that the <em>p</em>-values following the
null distribution are independent and uniformly distributed.</p>
<p>The BH procedure can be described as follow:
Step 1 : Let <span class="math inline">\(p_{1} \leq p_{2} \leq \dots \leq p_{D}\)</span> be the observed <em>p</em>-values.</p>
<p>Step 2 : Calculate
<span class="math display">\[\hat{k} = \underset{1\leq k \leq D}{\text{argmax}} \lbrace k:p_k \leq \alpha k/D \rbrace.\]</span></p>
<p>Step 3 : If <span class="math inline">\(\hat{k}\)</span> exists, then reject the null hypothesis corresponding
to <span class="math inline">\(p_1 \leq \dots \leq p_k\)</span>. If not, accept the null hypothesis for
all tests.</p>
<p><span class="citation">(Benjamini and Hochberg <a href="#ref-benjamini_controlling_1995">1995</a>)</span> have shown that the FDR is upper-bounded
by: <span class="math display">\[\text{FDR} \leq \alpha d_0/D,\]</span> with <span class="math inline">\(d_0\)</span> the number of true null
hypothesis and have shown that this upper bounding is also true for
positively dependent test statistics, i.e. when the distribution of
<em>p</em>-values fulfils the Weak Positive Regression Dependency Property
(WPRDS).</p>
<p>Since the BH procedure controls the FDR at a level of <span class="math inline">\(\alpha d_0/D\)</span>
instead of <span class="math inline">\(\alpha\)</span>, a lot of work has been done in order to achieve a
better level, mainly by trying to estimate <span class="math inline">\(d_0\)</span> (see <span class="citation">(Roquain <a href="#ref-roquain2010type">2010</a>)</span>
and references therein for more details).</p>

</div>
</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-fisher1935statistical">
<p>Fisher, Ronald A. 1935. “Statistical Methods for Research Workers.” <em>Edinburgh: Oliver and Boyd, 1934 and the Logic of Inductive Interence; Royal Statistical Society</em> 98: S–39.</p>
</div>
<div id="ref-neyman1933testing">
<p>Neyman, Jerzy, and Egon S Pearson. 1933. “The Testing of Statistical Hypotheses in Relation to Probabilities a Priori.” In <em>Mathematical Proceedings of the Cambridge Philosophical Society</em>, 29:492–510. Cambridge University Press.</p>
</div>
<div id="ref-pearson1900on">
<p>Pearson, Karl. 1900. “On the Criterion That a Given System of Deviations from the Probable in the Case of a Correlated System of Variables Is Such That It Can Be Reasonably Supposed to Have Arisen from Random Sampling.” <em>The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science</em> 50 (302): 157–75.</p>
</div>
<div id="ref-wood_generalized_2006">
<p>Wood, Simon N. 2006. <em>Generalized Additive Models: An Introduction with R</em>. crcpress. <a href="https://www.crcpress.com/Generalized-Additive-Models-An-Introduction-with-R/Wood/p/book/9781584884743">https://www.crcpress.com/Generalized-Additive-Models-An-Introduction-with-R/Wood/p/book/9781584884743</a>.</p>
</div>
<div id="ref-bonferroni1936teoria">
<p>Bonferroni, C. 1936. “Teoria Statistica Delle Classi E Calcolo Delle Probabilita.” <em>Pubblicazioni Del R Istituto Superiore Di Scienze Economiche E Commericiali Di Firenze</em> 8: 3–62.</p>
</div>
<div id="ref-sidak1967rectangular">
<p>Šidák, Zbyněk. 1967. “Rectangular Confidence Regions for the Means of Multivariate Normal Distributions.” <em>Journal of the American Statistical Association</em> 62 (318): 626–33.</p>
</div>
<div id="ref-holm1979simple">
<p>Holm, Sture. 1979a. “A Simple Sequentially Rejective Multiple Test Procedure.” <em>Scandinavian Journal of Statistics</em>, 65–70.</p>
</div>
<div id="ref-benjamini_controlling_1995">
<p>Benjamini, Yoav, and Yosef Hochberg. 1995. “Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing.” <em>Journal of the Royal Statistical Society: Series B</em> 57 (1): 289–300.</p>
</div>
<div id="ref-roquain2010type">
<p>Roquain, Etienne. 2010. “Type I Error Rate Control for Testing Many Hypotheses: A Survey with Proofs.” <em>arXiv Preprint arXiv:1012.4078</em>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="combining-cluster-analysis-and-variable-selection.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="asso.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": ["book.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
