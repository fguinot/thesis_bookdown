<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>4.2 Method | book.utf8.md</title>
  <meta name="description" content="PdD thesis">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="4.2 Method | book.utf8.md />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="PdD thesis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.2 Method | book.utf8.md />
  
  <meta name="twitter:description" content="PdD thesis" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introleos.html">
<link rel="next" href="numsim.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistical learning for omics association and interactions studies based on blockwise feature compression</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i>General introduction</a></li>
<li class="chapter" data-level="1" data-path="genet.html"><a href="genet.html"><i class="fa fa-check"></i><b>1</b> Basic concepts of molecular genetics</a><ul>
<li class="chapter" data-level="1.1" data-path="genome.html"><a href="genome.html"><i class="fa fa-check"></i><b>1.1</b> Genome description</a></li>
<li class="chapter" data-level="1.2" data-path="genome-sequencing.html"><a href="genome-sequencing.html"><i class="fa fa-check"></i><b>1.2</b> Genome sequencing</a><ul>
<li class="chapter" data-level="1.2.1" data-path="genome-sequencing.html"><a href="genome-sequencing.html#DNAseq"><i class="fa fa-check"></i><b>1.2.1</b> DNA sequencing</a></li>
<li class="chapter" data-level="1.2.2" data-path="genome-sequencing.html"><a href="genome-sequencing.html#sequence-assembly"><i class="fa fa-check"></i><b>1.2.2</b> Sequence assembly</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html"><i class="fa fa-check"></i><b>1.3</b> DNA polymorphism</a><ul>
<li class="chapter" data-level="1.3.1" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html#restriction-fragment-length-polymorphisms-rflp"><i class="fa fa-check"></i><b>1.3.1</b> Restriction Fragment Length Polymorphisms (RFLP)</a></li>
<li class="chapter" data-level="1.3.2" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html#simple-sequence-length-polymorphisms-sslp"><i class="fa fa-check"></i><b>1.3.2</b> Simple Sequence Length Polymorphisms (SSLP)</a></li>
<li class="chapter" data-level="1.3.3" data-path="dna-polymorphism.html"><a href="dna-polymorphism.html#single-nucleotide-polymorphisms-snp"><i class="fa fa-check"></i><b>1.3.3</b> Single Nucleotide Polymorphisms (SNP)</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="linkage.html"><a href="linkage.html"><i class="fa fa-check"></i><b>1.4</b> Linkage and partial linkage for genetic mapping</a></li>
<li class="chapter" data-level="1.5" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html"><i class="fa fa-check"></i><b>1.5</b> Basic concepts in population genetics</a><ul>
<li class="chapter" data-level="1.5.1" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html#HWE"><i class="fa fa-check"></i><b>1.5.1</b> Hardy-Weinberg equilibrium in large population</a></li>
<li class="chapter" data-level="1.5.2" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html#genetic-drift-in-small-population"><i class="fa fa-check"></i><b>1.5.2</b> Genetic drift in small population</a></li>
<li class="chapter" data-level="1.5.3" data-path="basic-concepts-in-population-genetics.html"><a href="basic-concepts-in-population-genetics.html#concept-of-heritability"><i class="fa fa-check"></i><b>1.5.3</b> Concept of heritability</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="LD.html"><a href="LD.html"><i class="fa fa-check"></i><b>1.6</b> Linkage disequilibrium</a><ul>
<li class="chapter" data-level="1.6.1" data-path="LD.html"><a href="LD.html#definition"><i class="fa fa-check"></i><b>1.6.1</b> Definition</a></li>
<li class="chapter" data-level="1.6.2" data-path="LD.html"><a href="LD.html#measure-of-ld"><i class="fa fa-check"></i><b>1.6.2</b> Measure of LD</a></li>
<li class="chapter" data-level="1.6.3" data-path="LD.html"><a href="LD.html#estimation-of-linkage-disequilibrium"><i class="fa fa-check"></i><b>1.6.3</b> Estimation of linkage disequilibrium</a></li>
<li class="chapter" data-level="1.6.4" data-path="LD.html"><a href="LD.html#origins-of-linkage-disequilibrium"><i class="fa fa-check"></i><b>1.6.4</b> Origins of linkage disequilibrium</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="haplo.html"><a href="haplo.html"><i class="fa fa-check"></i><b>1.7</b> Structure of haplotype blocks in the human genome</a><ul>
<li class="chapter" data-level="" data-path="haplo.html"><a href="haplo.html#definition-of-haplotype-blocks"><i class="fa fa-check"></i>Definition of haplotype blocks</a></li>
<li class="chapter" data-level="" data-path="haplo.html"><a href="haplo.html#patterns-in-human-genome"><i class="fa fa-check"></i>Patterns in human genome</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="stat.html"><a href="stat.html"><i class="fa fa-check"></i><b>2</b> Statistical context</a><ul>
<li class="chapter" data-level="2.1" data-path="notations.html"><a href="notations.html"><i class="fa fa-check"></i><b>2.1</b> Notations</a></li>
<li class="chapter" data-level="2.2" data-path="concepts-of-statistical-learning.html"><a href="concepts-of-statistical-learning.html"><i class="fa fa-check"></i><b>2.2</b> Concepts of statistical learning</a><ul>
<li class="chapter" data-level="2.2.1" data-path="concepts-of-statistical-learning.html"><a href="concepts-of-statistical-learning.html#prediction"><i class="fa fa-check"></i><b>2.2.1</b> Prediction</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="parametric.html"><a href="parametric.html"><i class="fa fa-check"></i><b>2.3</b> Parametric methods</a><ul>
<li class="chapter" data-level="2.3.1" data-path="parametric.html"><a href="parametric.html#linmod"><i class="fa fa-check"></i><b>2.3.1</b> Linear models</a></li>
<li class="chapter" data-level="2.3.2" data-path="parametric.html"><a href="parametric.html#penalized"><i class="fa fa-check"></i><b>2.3.2</b> Penalized linear regression</a></li>
<li class="chapter" data-level="2.3.3" data-path="parametric.html"><a href="parametric.html#glm"><i class="fa fa-check"></i><b>2.3.3</b> Generalized linear models</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="non-parametric.html"><a href="non-parametric.html"><i class="fa fa-check"></i><b>2.4</b> Splines and generalized additive models: Moving beyond linearit</a><ul>
<li class="chapter" data-level="2.4.1" data-path="non-parametric.html"><a href="non-parametric.html#introduction"><i class="fa fa-check"></i><b>2.4.1</b> Introduction</a></li>
<li class="chapter" data-level="2.4.2" data-path="non-parametric.html"><a href="non-parametric.html#splines"><i class="fa fa-check"></i><b>2.4.2</b> Regression splines</a></li>
<li class="chapter" data-level="2.4.3" data-path="non-parametric.html"><a href="non-parametric.html#mathrmb-splines"><i class="fa fa-check"></i><b>2.4.3</b> <span class="math inline">\(\mathrm{B}\)</span>-splines</a></li>
<li class="chapter" data-level="2.4.4" data-path="non-parametric.html"><a href="non-parametric.html#smoothing"><i class="fa fa-check"></i><b>2.4.4</b> Cubic smoothing splines</a></li>
<li class="chapter" data-level="2.4.5" data-path="non-parametric.html"><a href="non-parametric.html#gam"><i class="fa fa-check"></i><b>2.4.5</b> Generalized additive models (GAM)</a></li>
<li class="chapter" data-level="2.4.6" data-path="non-parametric.html"><a href="non-parametric.html#hgam"><i class="fa fa-check"></i><b>2.4.6</b> High-dimensional generalized additive models (HGAM)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html"><i class="fa fa-check"></i><b>2.5</b> Combining cluster analysis and variable selection</a><ul>
<li class="chapter" data-level="2.5.1" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html#CAH"><i class="fa fa-check"></i><b>2.5.1</b> Hierarchical clustering</a></li>
<li class="chapter" data-level="2.5.2" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html#HCAR"><i class="fa fa-check"></i><b>2.5.2</b> Hierarchical Clustering and Averaging Regression</a></li>
<li class="chapter" data-level="2.5.3" data-path="combining-cluster-analysis-and-variable-selection.html"><a href="combining-cluster-analysis-and-variable-selection.html#MLGL"><i class="fa fa-check"></i><b>2.5.3</b> Multi-Layer Group-Lasso (MLGL)</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="hypothesis.html"><a href="hypothesis.html"><i class="fa fa-check"></i><b>2.6</b> Statistical testing of significance</a><ul>
<li class="chapter" data-level="2.6.1" data-path="hypothesis.html"><a href="hypothesis.html#introduction-1"><i class="fa fa-check"></i><b>2.6.1</b> Introduction</a></li>
<li class="chapter" data-level="2.6.2" data-path="hypothesis.html"><a href="hypothesis.html#chi2"><i class="fa fa-check"></i><b>2.6.2</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="2.6.3" data-path="hypothesis.html"><a href="hypothesis.html#LRT"><i class="fa fa-check"></i><b>2.6.3</b> Likelihood ratio test</a></li>
<li class="chapter" data-level="2.6.4" data-path="hypothesis.html"><a href="hypothesis.html#pvalGAM"><i class="fa fa-check"></i><b>2.6.4</b> Calculation of <em>p</em>-values in GAM</a></li>
<li class="chapter" data-level="2.6.5" data-path="hypothesis.html"><a href="hypothesis.html#multiple"><i class="fa fa-check"></i><b>2.6.5</b> Multiple testing comparison</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="asso.html"><a href="asso.html"><i class="fa fa-check"></i><b>3</b> Genome-Wide Association Studies</a><ul>
<li class="chapter" data-level="3.1" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="genoquality.html"><a href="genoquality.html"><i class="fa fa-check"></i><b>3.2</b> Genotype quality control</a><ul>
<li class="chapter" data-level="3.2.1" data-path="genoquality.html"><a href="genoquality.html#deviation-from-hwe."><i class="fa fa-check"></i><b>3.2.1</b> Deviation from HWE.</a></li>
<li class="chapter" data-level="3.2.2" data-path="genoquality.html"><a href="genoquality.html#missing-data."><i class="fa fa-check"></i><b>3.2.2</b> Missing data.</a></li>
<li class="chapter" data-level="3.2.3" data-path="genoquality.html"><a href="genoquality.html#distribution-of-test-statistics."><i class="fa fa-check"></i><b>3.2.3</b> Distribution of test statistics.</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="OR.html"><a href="OR.html"><i class="fa fa-check"></i><b>3.3</b> Disease penetrance and odds ratio</a></li>
<li class="chapter" data-level="3.4" data-path="SMA.html"><a href="SMA.html"><i class="fa fa-check"></i><b>3.4</b> Single Marker Analysis</a><ul>
<li class="chapter" data-level="3.4.1" data-path="SMA.html"><a href="SMA.html#pearsons-chi2-statistic"><i class="fa fa-check"></i><b>3.4.1</b> Pearson’s <span class="math inline">\(\chi^2\)</span> statistic</a></li>
<li class="chapter" data-level="3.4.2" data-path="SMA.html"><a href="SMA.html#cochran-armitage-trend-test"><i class="fa fa-check"></i><b>3.4.2</b> Cochran-Armitage trend test</a></li>
<li class="chapter" data-level="3.4.3" data-path="SMA.html"><a href="SMA.html#logitGWAS"><i class="fa fa-check"></i><b>3.4.3</b> Logistic regression and likelihood ratio test</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="GWASlimits.html"><a href="GWASlimits.html"><i class="fa fa-check"></i><b>3.5</b> Limitations</a></li>
<li class="chapter" data-level="3.6" data-path="popstructure.html"><a href="popstructure.html"><i class="fa fa-check"></i><b>3.6</b> Population structure</a><ul>
<li class="chapter" data-level="3.6.1" data-path="popstructure.html"><a href="popstructure.html#genomic-control"><i class="fa fa-check"></i><b>3.6.1</b> Genomic control</a></li>
<li class="chapter" data-level="3.6.2" data-path="popstructure.html"><a href="popstructure.html#structured-association"><i class="fa fa-check"></i><b>3.6.2</b> Structured association</a></li>
<li class="chapter" data-level="3.6.3" data-path="popstructure.html"><a href="popstructure.html#PCC"><i class="fa fa-check"></i><b>3.6.3</b> Principle components correction</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="multiloc.html"><a href="multiloc.html"><i class="fa fa-check"></i><b>3.7</b> Multi-locus analysis</a><ul>
<li class="chapter" data-level="3.7.1" data-path="multiloc.html"><a href="multiloc.html#haplotype-based-approaches"><i class="fa fa-check"></i><b>3.7.1</b> Haplotype-based approaches</a></li>
<li class="chapter" data-level="3.7.2" data-path="multiloc.html"><a href="multiloc.html#rare-variant"><i class="fa fa-check"></i><b>3.7.2</b> Rare-variant association analysis</a></li>
<li class="chapter" data-level="3.7.3" data-path="multiloc.html"><a href="multiloc.html#adjclust"><i class="fa fa-check"></i><b>3.7.3</b> LD based approach to variable selection in GWAS</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="LEOS.html"><a href="LEOS.html"><i class="fa fa-check"></i><b>4</b> Learning the Optimal in GWAS through hierarchical SNP aggregation</a><ul>
<li class="chapter" data-level="4.1" data-path="introleos.html"><a href="introleos.html"><i class="fa fa-check"></i><b>4.1</b> Related work</a></li>
<li class="chapter" data-level="4.2" data-path="leosmethod.html"><a href="leosmethod.html"><i class="fa fa-check"></i><b>4.2</b> Method</a><ul>
<li class="chapter" data-level="4.2.1" data-path="leosmethod.html"><a href="leosmethod.html#CHAC"><i class="fa fa-check"></i><b>4.2.1</b> Step 1. Constrained-HAC</a></li>
<li class="chapter" data-level="4.2.2" data-path="leosmethod.html"><a href="leosmethod.html#Dstar"><i class="fa fa-check"></i><b>4.2.2</b> Step 2. Dimension reduction function</a></li>
<li class="chapter" data-level="4.2.3" data-path="leosmethod.html"><a href="leosmethod.html#cutree"><i class="fa fa-check"></i><b>4.2.3</b> Step 3. Optimal number of groups estimation</a></li>
<li class="chapter" data-level="4.2.4" data-path="leosmethod.html"><a href="leosmethod.html#step4"><i class="fa fa-check"></i><b>4.2.4</b> Step 4. Multiple testing on aggregated-SNP variables</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="numsim.html"><a href="numsim.html"><i class="fa fa-check"></i><b>4.3</b> Numerical simulations</a><ul>
<li class="chapter" data-level="4.3.1" data-path="numsim.html"><a href="numsim.html#simupheno"><i class="fa fa-check"></i><b>4.3.1</b> Simulation of the case-control phenotype</a></li>
<li class="chapter" data-level="4.3.2" data-path="numsim.html"><a href="numsim.html#perfeval"><i class="fa fa-check"></i><b>4.3.2</b> Performance evaluation</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>4.4</b> Results</a><ul>
<li class="chapter" data-level="4.4.1" data-path="results.html"><a href="results.html#results-and-discussions-of-the-numerical-simulations"><i class="fa fa-check"></i><b>4.4.1</b> Results and discussions of the numerical simulations</a></li>
<li class="chapter" data-level="4.4.2" data-path="results.html"><a href="results.html#performance-results-for-simulated-data."><i class="fa fa-check"></i><b>4.4.2</b> Performance results for simulated data.</a></li>
<li class="chapter" data-level="4.4.3" data-path="results.html"><a href="results.html#leosappli"><i class="fa fa-check"></i><b>4.4.3</b> Application in Wellcome Trust Case Control Consortium(WTCCC) and Ankylosing Spondylitis (AS) studies</a></li>
<li class="chapter" data-level="4.4.4" data-path="results.html"><a href="results.html#realdata"><i class="fa fa-check"></i><b>4.4.4</b> Results in WTCCC and AS studies</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="leosgam.html"><a href="leosgam.html"><i class="fa fa-check"></i><b>4.5</b> Generalized additive models in GWAS</a><ul>
<li class="chapter" data-level="4.5.1" data-path="leosgam.html"><a href="leosgam.html#comparison-of-predictive-power"><i class="fa fa-check"></i><b>4.5.1</b> Comparison of predictive power</a></li>
<li class="chapter" data-level="4.5.2" data-path="leosgam.html"><a href="leosgam.html#results-of-univariate-smoothing-splines-on-aggregated-snp"><i class="fa fa-check"></i><b>4.5.2</b> Results of univariate smoothing splines on aggregated-SNP</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="discussions.html"><a href="discussions.html"><i class="fa fa-check"></i><b>4.6</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sicomore.html"><a href="sicomore.html"><i class="fa fa-check"></i><b>5</b> Selection of interaction effects in compressed multiple omics representation</a><ul>
<li class="chapter" data-level="5.1" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>5.1</b> Introduction</a><ul>
<li class="chapter" data-level="5.1.1" data-path="introduction-3.html"><a href="introduction-3.html#background-1"><i class="fa fa-check"></i><b>5.1.1</b> Background</a></li>
<li class="chapter" data-level="5.1.2" data-path="introduction-3.html"><a href="introduction-3.html#combining-genome-and-metagenome-analyses."><i class="fa fa-check"></i><b>5.1.2</b> Combining genome and metagenome analyses.</a></li>
<li class="chapter" data-level="5.1.3" data-path="introduction-3.html"><a href="introduction-3.html#taking-structures-into-account-in-association-studies."><i class="fa fa-check"></i><b>5.1.3</b> Taking structures into account in association studies.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="modelsicomore.html"><a href="modelsicomore.html"><i class="fa fa-check"></i><b>5.2</b> Learning with complementary datasets</a><ul>
<li class="chapter" data-level="5.2.1" data-path="modelsicomore.html"><a href="modelsicomore.html#setting-and-notations"><i class="fa fa-check"></i><b>5.2.1</b> Setting and notations</a></li>
<li class="chapter" data-level="5.2.2" data-path="modelsicomore.html"><a href="modelsicomore.html#interactions-in-linear-models"><i class="fa fa-check"></i><b>5.2.2</b> Interactions in linear models</a></li>
<li class="chapter" data-level="5.2.3" data-path="modelsicomore.html"><a href="modelsicomore.html#compressdata"><i class="fa fa-check"></i><b>5.2.3</b> Compact model</a></li>
<li class="chapter" data-level="5.2.4" data-path="modelsicomore.html"><a href="modelsicomore.html#recoverinteractions"><i class="fa fa-check"></i><b>5.2.4</b> Recovering relevant interactions</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="implementation.html"><a href="implementation.html"><i class="fa fa-check"></i><b>5.3</b> Method</a><ul>
<li class="chapter" data-level="5.3.1" data-path="implementation.html"><a href="implementation.html#preprocess"><i class="fa fa-check"></i><b>5.3.1</b> Preprocessing of the data</a></li>
<li class="chapter" data-level="5.3.2" data-path="implementation.html"><a href="implementation.html#preprocessing-of-metagenomic-data"><i class="fa fa-check"></i><b>5.3.2</b> Preprocessing of metagenomic data</a></li>
<li class="chapter" data-level="5.3.3" data-path="implementation.html"><a href="implementation.html#structure"><i class="fa fa-check"></i><b>5.3.3</b> Structuring the data</a></li>
<li class="chapter" data-level="5.3.4" data-path="implementation.html"><a href="implementation.html#using-the-structure-efficiently"><i class="fa fa-check"></i><b>5.3.4</b> Using the structure efficiently</a></li>
<li class="chapter" data-level="5.3.5" data-path="implementation.html"><a href="implementation.html#identification-of-relevant-supervariables"><i class="fa fa-check"></i><b>5.3.5</b> Identification of relevant supervariables</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="XPsimu.html"><a href="XPsimu.html"><i class="fa fa-check"></i><b>5.4</b> Numerical simulations</a><ul>
<li class="chapter" data-level="5.4.1" data-path="XPsimu.html"><a href="XPsimu.html#data-generation"><i class="fa fa-check"></i><b>5.4.1</b> Data generation</a></li>
<li class="chapter" data-level="5.4.2" data-path="XPsimu.html"><a href="XPsimu.html#generation-of-the-phenotype"><i class="fa fa-check"></i><b>5.4.2</b> Generation of the phenotype</a></li>
<li class="chapter" data-level="5.4.3" data-path="XPsimu.html"><a href="XPsimu.html#comparison-of-methods"><i class="fa fa-check"></i><b>5.4.3</b> Comparison of methods</a></li>
<li class="chapter" data-level="5.4.4" data-path="XPsimu.html"><a href="XPsimu.html#evaluation-metrics"><i class="fa fa-check"></i><b>5.4.4</b> Evaluation metrics</a></li>
<li class="chapter" data-level="5.4.5" data-path="XPsimu.html"><a href="XPsimu.html#performance-results"><i class="fa fa-check"></i><b>5.4.5</b> Performance results</a></li>
<li class="chapter" data-level="5.4.6" data-path="XPsimu.html"><a href="XPsimu.html#computational-time"><i class="fa fa-check"></i><b>5.4.6</b> Computational time</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="XPINRA.html"><a href="XPINRA.html"><i class="fa fa-check"></i><b>5.5</b> Application on real data: rhizosphere of <em>Medicago truncatula</em></a><ul>
<li class="chapter" data-level="5.5.1" data-path="XPINRA.html"><a href="XPINRA.html#material"><i class="fa fa-check"></i><b>5.5.1</b> Material</a></li>
<li class="chapter" data-level="5.5.2" data-path="XPINRA.html"><a href="XPINRA.html#analysis"><i class="fa fa-check"></i><b>5.5.2</b> Analysis</a></li>
<li class="chapter" data-level="5.5.3" data-path="XPINRA.html"><a href="XPINRA.html#results-1"><i class="fa fa-check"></i><b>5.5.3</b> Results</a></li>
<li class="chapter" data-level="5.5.4" data-path="XPINRA.html"><a href="XPINRA.html#results-on-root-shoot-ratio"><i class="fa fa-check"></i><b>5.5.4</b> Results on Root Shoot Ratio</a></li>
<li class="chapter" data-level="5.5.5" data-path="XPINRA.html"><a href="XPINRA.html#results-on-specific-nitrogen-uptake"><i class="fa fa-check"></i><b>5.5.5</b> Results on Specific Nitrogen Uptake</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="discussions-1.html"><a href="discussions-1.html"><i class="fa fa-check"></i><b>5.6</b> Discussions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html"><i class="fa fa-check"></i>Conclusions</a><ul>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html#discussions-on-leos-algorithm"><i class="fa fa-check"></i>Discussions on LEOS algorithm</a></li>
<li class="chapter" data-level="" data-path="conclusions.html"><a href="conclusions.html#discussions-on-sicomore-algorithm"><i class="fa fa-check"></i>Discussions on SICOMORE algorithm</a></li>
<li class="chapter" data-level="" data-path="perspectives.html"><a href="perspectives.html"><i class="fa fa-check"></i>Perspectives</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="leosmethod" class="section level2">
<h2><span class="header-section-number">4.2</span> Method</h2>
<p>In this section we describe a new method for performing GWAS using a
four-step method that combines unsupervised and supervised learning
techniques. This method improves the detection power of genomic regions
implied in a disease while maintaining a good interpretability.</p>
<p>This method consists in:</p>
<ul>
<li><p><strong>Step 1</strong>: Performing a spatially constrained Hierarchical Agglomerative
Clustering of the additively coded SNP matrix
<span class="math inline">\(\mathbf{Z} \in \mathbb{R}^{n \times D}\)</span> using the algorithm <a href="multiloc.html#adjclust">3.7.3</a>
developed by <span class="citation">(A. Dehman, Ambroise, and Neuvial <a href="#ref-dehman_performance_2015">2015</a>)</span>.</p></li>
<li><p><strong>Step 2</strong>: Applying a function to reduce the dimension of <span class="math inline">\(\mathbf{Z}\)</span> using the group
definition from the constrained-HAC. This step is described and
illustrated in Figure <a href="leosmethod.html#fig:step2">4.2</a>.</p></li>
<li><p><strong>Step 3</strong>: Estimating the optimal number of groups using a supervised learning
approach to find the best cut into the hierarchical tree (cut level
algorithm). This algorithm combines Steps 1 and 2 into an iterative
process.</p></li>
<li><p><strong>Step 4</strong>: Applying the function defined in Step 2 to each group identified in
Step 3 to construct a new covariate matrix and perform multiple
hypotheses testing on each new covariate to find significant
associations with a disease phenotype <span class="math inline">\(\mathbf{y}\)</span>.</p></li>
</ul>
<p>We entitled this method <strong>LEOS</strong> for <strong>LE</strong>arning the <strong>O</strong>ptimale
<strong>S</strong>cale in GWAS, implemented in a web server too available at
<a href="http://stat.genopole.cnrs.fr/leos" class="uri">http://stat.genopole.cnrs.fr/leos</a>.</p>
<div id="CHAC" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Step 1. Constrained-HAC</h3>
<p>To take into account the structure of the genome in haplotype blocks, we
group the predictors (SNP) according to their LD in order to create a
new predictor matrix which reflects the structure of the genome. We use
the algorithm <em>adjclust</em> developed by <span class="citation">(A. Dehman, Ambroise, and Neuvial <a href="#ref-dehman_performance_2015">2015</a>)</span> which
consists in only allowing adjacent clusters to be merged, as described
in Section <a href="multiloc.html#adjclust">3.7.3</a>. This algorithm is available via the <code>R</code>
package at <a href="https://cran.r-project.org/web/packages/adjclust" class="uri">https://cran.r-project.org/web/packages/adjclust</a>.</p>
<p>A similar adjacency-constrained hierarchical clustering using Ward’s
linkage have already been proposed in <span class="citation">(Grimm <a href="#ref-grimm1987coniss">1987</a>)</span>, together with
an algorithm called CONISS for Constrained Incremental Sums of Squares.
However, the quadratic complexity of its implementation prevents it from
being used on large genomic data sets.</p>
<p>In the context of GWAS, it is nevertheless possible to circumvent this
problem by assuming that the similarity between physically distant SNP
is small due to the particular LD structure of the genome, as seen in
Section <a href="haplo.html#haplo">1.7</a>.</p>
<p>More specifically, we assume that the <span class="math inline">\(D\times D\)</span> matrix of pairwise
similarities defined as <span class="math inline">\(\mathbf{S} = dist(i,j)_{1 \leq i,j\leq D}\)</span> is a band
matrix of bandwidth <span class="math inline">\(h + 1\)</span>, where <span class="math inline">\(h \in [1,\dots,D]: dist(i,j) = 0\)</span>
for <span class="math inline">\(|i-j| \geq h\)</span> and <span class="math inline">\(D\)</span> the number of naturally ordered objects (SNP)
to classify. This assumption is not restrictive, as taking <span class="math inline">\(h = D\)</span>
always works. However, considering the large dimension of genomic data,
we are mostly interested in the case where <span class="math inline">\(h \ll D\)</span>.</p>
<p>Adjclust is an algorithm that uses this band similarity assumption to
improve time and space complexity in the context of a genome-wide
hierarchical clustering. The main features of this algorithm are the
constant-time calculation of each of the Ward’s linkage involved in the
spatially-constrained HAC and the storage of the candidate merges in a
min-heap.</p>
<div id="wards-linkage-as-a-function-of-pre-calculated-sums." class="section level4">
<h4><span class="header-section-number">4.2.1.1</span> Ward’s linkage as a function of pre-calculated sums.</h4>
<p>To decrease the complexity in the calculation of each of the Ward’s
linkage, the trick is to note the sum of all similarities in any cluster
<span class="math inline">\(K=\{u, \dots , v-1\}\)</span> of size <span class="math inline">\(k = v-u\)</span> as a sum of elements in the
first <span class="math inline">\(\min(h,k)\)</span> subdiagonals of <span class="math inline">\(\mathbf{S}\)</span>.</p>
<p>To see this, we define, for <span class="math inline">\(1 \leq r,l \leq D\)</span>, the sum of all elements
of <span class="math inline">\(\mathbf{S}\)</span> in the first <span class="math inline">\(l\)</span> subdiagonals of the upper-right <span class="math inline">\(r \times r\)</span>
block of <span class="math inline">\(S\)</span> as
<span class="math display">\[P(r,l) = \sum_{1 \leq i,j \leq r, |i-j| \ &lt; l} dist(i,j) ,\]</span> and
symmetrically, <span class="math inline">\(\bar{P}(r, l) = P(p+1-r, l)\)</span>. Because <span class="math inline">\(P\)</span> and <span class="math inline">\(\bar{P}\)</span>
are sums of elements in pencil-shaped areas, they are called <em>forward pencil</em> and <em>backward pencil</em>, as illustrated in Figure <a href="leosmethod.html#fig:penciltrick">4.1</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:penciltrick"></span>
<img src="book_files/figure-html/penciltrick-1.png" alt="Example of forward pencils (in yellow and green) and backward pencils (in green and blue), and illustration of Equation (4.1) for cluster \(K=\{u, \dots , v-1\}\). Left: cluster smaller than bandwidth (\(k \leq h\)); right: cluster larger than bandwidth \(k \geq h\)." width="90%" />
<p class="caption">
Figure 4.1: Example of forward pencils (in yellow and green) and backward pencils (in green and blue), and illustration of Equation <a href="leosmethod.html#eq:pencilsums">(4.1)</a> for cluster <span class="math inline">\(K=\{u, \dots , v-1\}\)</span>. Left: cluster smaller than bandwidth (<span class="math inline">\(k \leq h\)</span>); right: cluster larger than bandwidth <span class="math inline">\(k \geq h\)</span>.
</p>
</div>
<p>The advantage of computing the sums <span class="math inline">\(P\)</span> and <span class="math inline">\(\bar{P}\)</span> is that they can
be used to calculate the sum <span class="math inline">\(S_{KK}\)</span> of all similarities in cluster <span class="math inline">\(K\)</span>
following the identity:
<span class="math display" id="eq:pencilsums">\[\begin{equation}
P(v, h_k) + \bar{P}(u, h_k) = S_{KK} + P(p, h_k)\,
\tag{4.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(h_k:=\min(h,k)\)</span> and <span class="math inline">\(P(p, h_k)\)</span> is the “full” pencil of bandwidth <span class="math inline">\(h_k\)</span>
(which also corresponds to <span class="math inline">\(\bar{P}(1, h_k)\)</span>). By construction, all the
bandwidths of the pencils involved are less than <span class="math inline">\(h\)</span>. Therefore, only
pencils <span class="math inline">\(P(u,k)\)</span> and <span class="math inline">\(\bar{P}(u,k)\)</span> with <span class="math inline">\(1 \leq u \leq p\)</span> and
<span class="math inline">\(1 \leq k \leq h\)</span> have to be pre-calculated, so that the total number of
pencils to calculate and stored is less than <span class="math inline">\(2ph\)</span>. By calculating these
pencils recursively using cumulative sums, the time complexity of the
pre-calculation step is <span class="math inline">\(ph\)</span> (see proof in <span class="citation">(Alia Dehman <a href="#ref-dehman2015spatial">2015</a><a href="#ref-dehman2015spatial">a</a>)</span>).</p>
</div>
<div id="storing-candidate-fusions-in-a-min-heap." class="section level4">
<h4><span class="header-section-number">4.2.1.2</span> Storing candidate fusions in a min-heap.</h4>
<p>Each iteration <span class="math inline">\(i\)</span> of the hierarchical agglomerative clustering
(Algorithm 1, Section <a href="combining-cluster-analysis-and-variable-selection.html#CAH">2.5.1</a>, consists in finding the
minimum of <span class="math inline">\(D-i\)</span> elements, corresponding to the candidate fusions
between the <span class="math inline">\(D-i+1\)</span> clusters, stored in a sorted list, and merging the
corresponding clusters. However, as the cost of deleting and inserting
an element in a sorted list is linear in <span class="math inline">\(D\)</span>, adjclust choose to reduce
the complexity by storing the candidate fusions in a partially-ordered
data structure called a <em>min-heap</em> <span class="citation">(Williams <a href="#ref-williams1964algorithm">1964</a>)</span>.</p>
<p>A min-heap is a binary tree structure constructed such that the value of
each node is smaller than the value of its two children. The advantage
of such structure is the cost trade-off they achieve between maintaining
the structure and finding the minimum element at each iteration. More
specifically, at the beginning of the clustering, the heap is
initialized with <span class="math inline">\(D-1\)</span> candidate fusions in <span class="math inline">\(\mathcal{O}(D \log(D))\)</span>.
Then, each of the <span class="math inline">\(D\)</span> iteration involves at most <span class="math inline">\(\mathcal{O}(\log(D))\)</span>
operations as:</p>
<ul>
<li><p>finding the best candidate fusion (root of the min heap) in <span class="math inline">\(\mathcal{O}(1)\)</span>,</p></li>
<li><p>creating a new cluster corresponding to this fusion in <span class="math inline">\(\mathcal{O}(1)\)</span>,</p></li>
<li><p>deleting the root of the min heap in <span class="math inline">\(\mathcal{O}(\log(D))\)</span>,</p></li>
<li><p>inserting two possible fusions in the min heap in <span class="math inline">\(\mathcal{O}(\log(D))\)</span>.</p></li>
</ul>
<p>Globally, with a space complexity of <span class="math inline">\(\mathcal{O}(Dh)\)</span>, corresponding to
the <span class="math inline">\(2Dh\)</span> pre-calculated pencils, and a time complexity of
<span class="math inline">\(\mathcal{O}(D(h + log(D))\)</span>, where <span class="math inline">\(\mathcal{O}(Dh)\)</span> comes from the
pre-calculation of pencils and <span class="math inline">\(\mathcal{O}(D\log(D))\)</span> from the <span class="math inline">\(D\)</span>
iterations of the algorithm, adjclust achieves a quasi-linear time
complexity and linear space complexity when <span class="math inline">\(h \ll D\)</span>.</p>
<p>In a GWAS application, the choice of <span class="math inline">\(h\)</span> will mainly depends on the
genotyping density and on the strength of the LD structure in the
studied population. In the evaluation of our method in both numerical
simulations <a href="numsim.html#perfeval">4.3.2</a> and real data application (Section
<a href="results.html#leosappli">4.4.3</a>), we set the value at <span class="math inline">\(h = 100\)</span>, having observed
that higher values had no impact on the performance of the method.</p>
</div>
</div>
<div id="Dstar" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Step 2. Dimension reduction function</h3>
<p>One way of addressing issues related to high-dimensional statistics (and
in particular the multiple testing burden that we mentioned in Section
<a href="hypothesis.html#multiple">2.6.5</a>) is to reduce the dimensionality of the predictor
matrix <span class="math inline">\(\mathbf{Z} \in \mathbb{R}^{N \times D}\)</span> by creating a reduced matrix
<span class="math inline">\(\tilde{\mathbf{X}}\)</span> with new covariates that nevertheless remain
representative of the initial matrix. This means reducing the number of
predictors <span class="math inline">\(D\)</span> to <span class="math inline">\(G \ll D\)</span>, with row <span class="math inline">\(\tilde{\mathbf{S}x}_{i}\)</span> the
<span class="math inline">\(G\)</span>-dimensional vector of new predictors for observation <span class="math inline">\(i\)</span>. In this
study we use a blockwise approach to construct a matrix of new
uncorrelated predictors <span class="math inline">\(\tilde{\mathbf{X}} \in \mathbb{R}^{N \times G}\)</span>,
with <span class="math inline">\(G\)</span> the number of groups in linkage disequilibrium identified via
the constrained agglomerative hierarchical clustering described in Step 1.</p>
<p>While classical methods use the initial set of covariates to predict a
phenotype, we propose combining a clustering model with a dimension
reduction approach in order to predict <span class="math inline">\(\mathbf{y}\)</span>. For each group identified
with the constrained-HAC, we apply a function to obtain a single
variable defined as the number of minor alleles present in the group.
For each observation <span class="math inline">\(i\)</span> and in each cluster <span class="math inline">\(g \in \left[1,\dots,G\right]\)</span>, the variable is defined as:
<span class="math display">\[\label{eq:aggregfun}
  \tilde{x}_{ig}~=~\sum_{d \in g} z_{id}.\]</span></p>
<p>We note that this function is close to the function used in the burden
tests (Section <a href="multiloc.html#rare-variant">3.7.2</a>) where we attribute a weight
<span class="math inline">\(\omega_d = 1\)</span> to each SNP since we do not particularly focus on rare
variants but rather on variants having a <span class="math inline">\(MAF \geq 5\%\)</span>. In order that
the values for the different groups are comparable, we eliminate the
effect of group size by centering and scaling the matrix <span class="math inline">\(\tilde{\mathbf{X}}\)</span>
to unit variance. In the remainder of the paper we will refer to the
covariates in <span class="math inline">\(\tilde{\mathbf{X}}\)</span> as <em>aggregated-SNP</em> variables.</p>

<div class="figure" style="text-align: center"><span id="fig:step2"></span>
<img src="book_files/figure-html/step2-1.png" alt="Schematic view of Step 2 of the algorithm to calculate the matrix of predictors \(\tilde{\mathbf{X}}^s\) at a given level \(s\) of the hierarchy." width="100%" />
<p class="caption">
Figure 4.2: Schematic view of Step 2 of the algorithm to calculate the matrix of predictors <span class="math inline">\(\tilde{\mathbf{X}}^s\)</span> at a given level <span class="math inline">\(s\)</span> of the hierarchy.
</p>
</div>
</div>
<div id="cutree" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Step 3. Optimal number of groups estimation</h3>
<p>Estimating the optimal number of groups to select, i.e. the level at
which the hierarchical clustering tree should be cut, is a fundamental
matter which impacts the relevance of the association analysis. As we
have seen in Section <a href="haplo.html#haplo">1.7</a>, it is known that the human genome is
structured into haplotype blocks with little or no within-block
recombination, but it is not easy to determine how these blocks are
allocated throughout the genome for a given set of SNP.</p>
<p>In the literature, in an unsupervised learning context, a number of
models have been proposed for determining the optimal number of groups
in a hierarchical clustering (see Section <a href="combining-cluster-analysis-and-variable-selection.html#CAH">2.5.1</a>). However, since
GWAS consist in evaluating the likelihood of the disease from genetic
markers, we propose an algorithm that makes use of the phenotype <span class="math inline">\(\mathbf{y}\)</span>
to determine the optimal number of clusters.</p>
<p>We propose here a supervised validation set approach to find this
optimum. Since this algorithm aims to identify phenotype-related SNP
clusters, it is necessary to split the dataset into two subsets to avoid
an inflation of type I errors in the testing procedure. One subset,
<span class="math inline">\([\mathbf{y}_{S1}, \mathbf{Z}_{S1}]\)</span> with sample size <span class="math inline">\(t_1 = n/2\)</span> is used to choose
the optimal cut and the second one, <span class="math inline">\([\mathbf{y}_{S2}, \mathbf{Z}_{S2}]\)</span> of sample
size <span class="math inline">\(t_2=n/2\)</span>, to perform the hypothesis testing in Step 4.</p>
<p>The algorithm we propose can be summarized as follows:</p>
<ul>
<li><p>Apply the constrained-HAC described in Step 1 on a training set
<span class="math inline">\(\mathbf{T} = \mathbf{X}^{train}_{S1} \subset \mathbf{X}_{S1}\)</span>, and for a given level <span class="math inline">\(s\)</span>
of the hierarchy we apply the dimension reduction function defined
above (Step 2) to each of the <span class="math inline">\(G_s\)</span> clusters to construct the matrix
<span class="math inline">\(\tilde{\mathbf{T}}^s = \left\lbrace \tilde{\mathbf{T}}_g^s \right\rbrace_{g = \mathcal{G}^s_1}^{\mathcal{G}^s_{G_s}}\)</span>.</p></li>
<li><p>Fit a ridge regression model to estimate the coefficients of the
predictors in <span class="math inline">\(\tilde{\mathbf{T}}^s\)</span>. We chose to resort on the ridge
regression model because, as we explained in Section
<a href="parametric.html#penalized">2.3.2</a>, it is known to have a better stability in
comparison to other penalized-regression models such as lasso
regression <span class="citation">(Bousquet and Elisseeff <a href="#ref-bousquet_stability_2002">2002</a>)</span>.</p></li>
<li><p>Once the ridge coefficients are estimated, we predict the phenotypic
values on the test set using the matrix <span class="math inline">\(\mathbf{U} = \mathbf{X}^{test}_{S2}\)</span> and
calculate either the mean test set error when the phenotype is
quantitative or the Area Under the ROC curve (AUC-ROC) when it is
binary.</p></li>
<li><p>Repeat with procedure for different levels in the hierarchy and
defined the optimal cut level <span class="math inline">\(s^*\)</span> (or equivalently the optimal
number of groups <span class="math inline">\(G^{s^*}\)</span>) as the level which maximizes the
prediction accuracy criterion.</p></li>
</ul>
<p><img src="book_files/figure-html/algocutlevel-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>At last, once the optimal number of groups <span class="math inline">\(G^*\)</span> has been determined, we
apply the function to each selected group and construct the matrix
<span class="math inline">\(\tilde{\mathbf{X}}^{(s^*)}\)</span>.</p>
</div>
<div id="step4" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Step 4. Multiple testing on aggregated-SNP variables</h3>
<p>Here we use a standard Single Marker Analysis, has described in Section
<a href="SMA.html#SMA">3.4</a>, to find associations with the phenotype, but instead of
calculating <span class="math inline">\(p\)</span>-value for each SNP in <span class="math inline">\(\mathbf{Z}\)</span>, we calculate <span class="math inline">\(p\)</span>-value for
each aggregated-SNP variable in <span class="math inline">\(\tilde{\mathbf{X}}^{(s^*)}_{S2} \subset \tilde{\mathbf{X}}^{(s^*)}\)</span>.</p>
<p>For each single-predictor model, we perform a Likelihood Ratio Test
(Section <a href="hypothesis.html#LRT">2.6.3</a>) where we compare the intercept-only model against
the single-predictor model and get for each predictor a <span class="math inline">\(p\)</span>-value using
the <span class="math inline">\(\tilde\chi^2\)</span> distribution.</p>
<p>As seen in Section <a href="hypothesis.html#multiple">2.6.5</a>, we need to compute an appropriate
significance threshold to control either the Family-Wise Error Rate or
the False Discovery Rate. However, as the FWER control methods reduce
the significance level according to the number of tests carried out in
the study, it is preferable, in this context, to control for the FDR to
be less stringent on the significance threshold. We therefore chose to
use the Benjamini-Hochberg procedure described in Section <a href="hypothesis.html#multiple">2.6.5</a> to
adjust the significance threshold.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-dehman_performance_2015">
<p>Dehman, A., C. Ambroise, and P. Neuvial. 2015. “Performance of a Blockwise Approach in Variable Selection Using Linkage Disequilibrium Information.” <em>BMC Bioinformatics</em> 16: 148.</p>
</div>
<div id="ref-grimm1987coniss">
<p>Grimm, Eric C. 1987. “CONISS: A Fortran 77 Program for Stratigraphically Constrained Cluster Analysis by the Method of Incremental Sum of Squares.” <em>Computers &amp; Geosciences</em> 13 (1): 13–35.</p>
</div>
<div id="ref-dehman2015spatial">
<p>Dehman, Alia. 2015a. “Spatial Clustering of Linkage Disequilibrium Blocks for Genome-Wide Association Studies.” PhD thesis, Université d’Evry Val d’Essonne; Université Paris-Saclay; Laboratoire de Mathématiques et Modélisation d’Evry.</p>
</div>
<div id="ref-williams1964algorithm">
<p>Williams, J. W. J. 1964. “Algorithm 232: Heapsort.” <em>Communications of the ACM</em> 7 (6): 347â348.</p>
</div>
<div id="ref-bousquet_stability_2002">
<p>Bousquet, O., and A. Elisseeff. 2002. “Stability and Generalization.” <em>Journal of Machine Learning Research</em> 2: 499–526.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introleos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="numsim.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": ["book.epub"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
